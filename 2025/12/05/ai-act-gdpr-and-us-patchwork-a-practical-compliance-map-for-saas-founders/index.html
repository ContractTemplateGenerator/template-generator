<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-901N2Y3CDZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-901N2Y3CDZ');
    </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Act, GDPR and US Patchwork: A Practical Compliance Map For SaaS Founders | Terms.Law</title>
  <meta name="description" content="In 2025, SaaS products using AI must navigate complex regulatory landscapes including the EU AI Act, GDPR, and various US laws. A practical guide outlines compl">
  <link rel="canonical" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/shared/styles.css">
</head>
<body>
  <div id="site-header"></div>
  <script src="/shared/header-loader.js"></script>

  <main>
    <article>
      <h1>AI Act, GDPR and US Patchwork: A Practical Compliance Map For SaaS Founders</h1>
      <div class="meta">Published: December 5, 2025 ‚Ä¢ AI</div>
      <div class="content">
<p>If you‚Äôre running a SaaS product in 2025 and using any kind of AI ‚Äì recommendation, scoring, fraud detection, chatbots, ‚Äúcopilot‚Äù features ‚Äì you are no longer just ‚Äúdoing tech.‚Äù</p>



<p>You are now in the blast radius of three overlapping regimes:</p>



<ul class="wp-block-list">
<li>The <strong>EU AI Act</strong> (risk-based, AI-specific).</li>



<li><strong>GDPR</strong> (and cousins like UK GDPR) wrapping around any personal data your AI touches.</li>



<li>The <strong>US patchwork</strong> of FTC enforcement, sector laws, and rapidly evolving state AI and privacy statutes.</li>
</ul>



<p>This guide is a practical map: what matters, where, and what a SaaS founder should actually <em>do</em> rather than just panic.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div id="ez-toc-container" class="ez-toc-v2_0_79_2 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction">
<div class="ez-toc-title-container">
<p class="ez-toc-title" style="cursor:inherit">Contents</p>
<span class="ez-toc-title-toggle"><a href="#" class="ez-toc-pull-right ez-toc-btn ez-toc-btn-xs ez-toc-btn-default ez-toc-toggle" aria-label="Toggle Table of Content"><span class="ez-toc-js-icon-con"><span class=""><span class="eztoc-hide" style="display:none;">Toggle</span><span class="ez-toc-icon-toggle-span"><svg style="fill: #999;color:#999" xmlns="http://www.w3.org/2000/svg" class="list-377408" width="20px" height="20px" viewBox="0 0 24 24" fill="none"><path d="M6 6H4v2h2V6zm14 0H8v2h12V6zM4 11h2v2H4v-2zm16 0H8v2h12v-2zM4 16h2v2H4v-2zm16 0H8v2h12v-2z" fill="currentColor"></path></svg><svg style="fill: #999;color:#999" class="arrow-unsorted-368013" xmlns="http://www.w3.org/2000/svg" width="10px" height="10px" viewBox="0 0 24 24" version="1.2" baseProfile="tiny"><path d="M18.2 9.3l-6.2-6.3-6.2 6.3c-.2.2-.3.4-.3.7s.1.5.3.7c.2.2.4.3.7.3h11c.3 0 .5-.1.7-.3.2-.2.3-.5.3-.7s-.1-.5-.3-.7zM5.8 14.7l6.2 6.3 6.2-6.3c.2-.2.3-.5.3-.7s-.1-.5-.3-.7c-.2-.2-.4-.3-.7-.3h-11c-.3 0-.5.1-.7.3-.2.2-.3.5-.3.7s.1.5.3.7z"/></svg></span></span></span></a></span></div>
<nav><ul class='ez-toc-list ez-toc-list-level-1 ' ><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-1" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%8C%8D_Where_Your_SaaS_Sits_On_The_Regulatory_Map" >üåç Where Your SaaS Sits On The Regulatory Map</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-2" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%A4%96_EU_AI_Act_Risk-Based_Obligations_For_AI-Driven_SaaS" >ü§ñ EU AI Act: Risk-Based Obligations For AI-Driven SaaS</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-3" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#Are_you_a_provider_deployer_distributor%E2%80%A6_or_just_embedding_someone_elses_API" >Are you a provider, deployer, distributor‚Ä¶ or just embedding someone else‚Äôs API?</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-4" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#What_%E2%80%9Chigh-risk%E2%80%9D_really_means_for_SaaS" >What ‚Äúhigh-risk‚Äù really means for SaaS</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-5" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%94%90_GDPR_Personal_Data_Rules_That_Wrap_Around_Your_AI" >üîê GDPR: Personal Data Rules That Wrap Around Your AI</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-6" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#GDPRs_automated_decision-making_profiling_rules" >GDPR‚Äôs automated decision-making &amp; profiling rules</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-7" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#GDPR_AI_Act_together" >GDPR + AI Act together</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-8" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%87%BA%F0%9F%87%B8_US_Patchwork_FTC_State_Privacy_Laws_And_New_AI_Statutes" >üá∫üá∏ US Patchwork: FTC, State Privacy Laws And New AI Statutes</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-9" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#FTC_%E2%80%9CNo_AI_exemption_from_the_laws_on_the_books%E2%80%9D" >FTC: ‚ÄúNo AI exemption from the laws on the books‚Äù</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-10" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#State_AI_and_privacy_laws" >State AI and privacy laws</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-11" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%93%90_NIST_AI_Risk_Management_Framework_The_De_Facto_Backbone" >üìê NIST AI Risk Management Framework: The De Facto Backbone</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-12" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%A7%AD_Crosswalk_What_You_Must_Actually_Do_By_Region" >üß≠ Crosswalk: What You Must Actually Do, By Region</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-13" href="https://terms.law/2025/12/05/ai-act-gdpr-and-us-patchwork-a-practical-compliance-map-for-saas-founders/#%F0%9F%9B%A0_Implementation_Roadmap_For_SaaS_Founders" >üõ† Implementation Roadmap For SaaS Founders</a></li></ul></nav></div>
<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%8C%8D_Where_Your_SaaS_Sits_On_The_Regulatory_Map"></span>üåç Where Your SaaS Sits On The Regulatory Map<span class="ez-toc-section-end"></span></h2>



<p>Start with a simple question: <em>Where are your users, and what does your product actually do with data and decisions?</em></p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>üåê SaaS footprint</th><th>What you‚Äôre exposed to</th><th>Why it matters for AI/ML features</th></tr></thead><tbody><tr><td><strong>EU/EEA customers (or targeting them)</strong></td><td><strong>EU AI Act</strong> + <strong>GDPR</strong></td><td>AI Act obligations (especially if your system is ‚Äúhigh-risk‚Äù or general-purpose), plus full GDPR regime for any personal data. (<a href="https://ttms.com/eu-ai-act-update-2025-code-of-practice-enforcement-industry-reactions/?utm_source=chatgpt.com">TTMS</a>)</td></tr><tr><td><strong>UK customers</strong></td><td><strong>UK GDPR</strong> + UK AI policy (no AI Act yet, but similar ADM/profiling rules)**</td><td>Almost identical concepts for automated decision-making and profiling; ICO already has detailed guidance. (<a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/automated-decision-making-and-profiling/what-does-the-uk-gdpr-say-about-automated-decision-making-and-profiling/?utm_source=chatgpt.com">ICO</a>)</td></tr><tr><td><strong>US only</strong></td><td>No federal AI code-of-conduct yet; <strong>FTC Act</strong>, sector laws (FCRA, ECOA, HIPAA, etc.), + state privacy &amp; AI laws</td><td>FTC‚Äôs ‚Äúno AI exemption‚Äù stance and state AG enforcement are filling the gap; Colorado AI Act and similar state moves add duties for ‚Äúhigh-risk‚Äù systems. (<a href="https://www.ftc.gov/industry/technology/artificial-intelligence?utm_source=chatgpt.com">Federal Trade Commission</a>)</td></tr><tr><td><strong>Global SaaS</strong></td><td>All of the above</td><td>You need a <strong>single internal standard</strong> (think NIST AI RMF) and then map** where you need extra documentation, notices, or opt-outs** by region. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</td></tr></tbody></table></figure>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A4%96_EU_AI_Act_Risk-Based_Obligations_For_AI-Driven_SaaS"></span>ü§ñ EU AI Act: Risk-Based Obligations For AI-Driven SaaS<span class="ez-toc-section-end"></span></h2>



<p>The EU AI Act formally entered into force in 2024, but its obligations are <strong>phased in</strong> over several years. (<a href="https://ttms.com/eu-ai-act-update-2025-code-of-practice-enforcement-industry-reactions/?utm_source=chatgpt.com">TTMS</a>)</p>



<p>Key milestones relevant to SaaS:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>üïí Date</th><th>What kicks in</th><th>Why a SaaS founder should care</th></tr></thead><tbody><tr><td><strong>Feb 2025</strong></td><td><strong>Bans on ‚Äúunacceptable‚Äù AI</strong> (e.g., social scoring, certain manipulative systems) start applying. (<a href="https://ttms.com/eu-ai-act-update-2025-code-of-practice-enforcement-industry-reactions/?utm_source=chatgpt.com">TTMS</a>)</td><td>If you do user scoring, risk or behavioral manipulation, you need to sanity-check that you‚Äôre not in prohibited territory.</td></tr><tr><td><strong>Aug 2, 2025</strong></td><td>Obligations for <strong>general-purpose AI (GPAI) / foundation models</strong> placed on the EU market after that date. (<a href="https://ttms.com/eu-ai-act-update-2025-code-of-practice-enforcement-industry-reactions/?utm_source=chatgpt.com">TTMS</a>)</td><td>If you <em>provide</em> a model or heavily fine-tuned foundation model, you may have GPAI duties (documentation, safety, cybersecurity, copyright safeguards, data summaries).</td></tr><tr><td><strong>2026‚Äì2027</strong></td><td>Gradual application of rules for <strong>high-risk AI systems</strong> (Annex III categories: credit scoring, hiring, education, essential services, law enforcement, etc.). (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td><td>Many B2B SaaS products (HR tech, lending, health tech, EdTech, ID verification) will fall into ‚Äúhigh-risk‚Äù and face significant obligations.</td></tr></tbody></table></figure>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Are_you_a_provider_deployer_distributor%E2%80%A6_or_just_embedding_someone_elses_API"></span>Are you a provider, deployer, distributor‚Ä¶ or just embedding someone else‚Äôs API?<span class="ez-toc-section-end"></span></h3>



<p>The AI Act splits responsibilities among:</p>



<ul class="wp-block-list">
<li><strong>Providers</strong> ‚Äì whoever places an AI system or GPAI model on the EU market under their name.</li>



<li><strong>Deployers</strong> ‚Äì organizations that use the AI system in their own operations (e.g., your EU customer using your scoring API in underwriting).</li>



<li><strong>Distributors / importers</strong> ‚Äì intermediaries who rebrand or resell. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>
</ul>



<p>For a typical SaaS founder:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Your role</th><th>Example</th><th>How the AI Act is likely to treat you</th></tr></thead><tbody><tr><td><strong>AI provider</strong></td><td>You build an AI-powered hiring SaaS that screens candidates for EU employers</td><td>Likely a <em>provider of a high-risk AI system</em> (employment in Annex III). You‚Äôll have to do risk management, data governance, technical documentation, human oversight, and conformity assessment. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td></tr><tr><td><strong>GPAI provider</strong></td><td>You offer a fine-tuned LLM as a standalone API to EU customers</td><td>You may be a <strong>GPAI provider</strong>, with obligations for transparency, technical documentation, copyright compliance, and security. (<a href="https://digital-strategy.ec.europa.eu/en/policies/guidelines-gpai-providers?utm_source=chatgpt.com">Digital Strategy</a>)</td></tr><tr><td><strong>Deployer only</strong></td><td>You offer a generic CRM SaaS but let customers plug in third-party AI tools via integrations</td><td>You‚Äôre a <strong>deployer</strong> when you configure and use those tools internally; the vendor of the AI system remains the ‚Äúprovider.‚Äù You still must ensure your use is compliant (especially if high-risk).</td></tr></tbody></table></figure>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="What_%E2%80%9Chigh-risk%E2%80%9D_really_means_for_SaaS"></span>What ‚Äúhigh-risk‚Äù really means for SaaS<span class="ez-toc-section-end"></span></h3>



<p>‚ÄúHigh-risk‚Äù is defined by <strong>use case</strong>, not marketing fluff. Examples SaaS founders care about: (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</p>



<ul class="wp-block-list">
<li>AI used in <strong>creditworthiness or credit scoring</strong> for natural persons.</li>



<li>AI used to <strong>screen job applicants</strong> or make decisions about promotions.</li>



<li>AI used in <strong>education</strong> to assign people to programs or evaluate exams.</li>



<li>AI used to determine access to <strong>essential services</strong> (healthcare, insurance, benefits).</li>
</ul>



<p>If your product does any of that <strong>in or for the EU</strong>, you‚Äôll be in the high-risk lane and need:</p>



<ul class="wp-block-list">
<li>A documented <strong>AI risk management system</strong>.</li>



<li><strong>Data governance</strong> measures (quality, representativeness, bias checks).</li>



<li><strong>Technical documentation</strong> and logs to show compliant design and monitoring.</li>



<li><strong>Human oversight mechanisms</strong> ‚Äì no fully unsupervised consequential decisions.</li>



<li>Conformity assessment and CE-marking style compliance before launch.</li>
</ul>



<p>Think of it as <em>GDPR-level paperwork, but specific to your model lifecycle.</em></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%94%90_GDPR_Personal_Data_Rules_That_Wrap_Around_Your_AI"></span>üîê GDPR: Personal Data Rules That Wrap Around Your AI<span class="ez-toc-section-end"></span></h2>



<p>The AI Act cares whether something is ‚ÄúAI‚Äù and how risky it is. <strong>GDPR</strong> cares any time you process <strong>personal data</strong>, AI or not. If you‚Äôre doing both, you‚Äôre inside both regimes at once.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="GDPRs_automated_decision-making_profiling_rules"></span>GDPR‚Äôs automated decision-making &amp; profiling rules<span class="ez-toc-section-end"></span></h3>



<p>Article 22 GDPR gives people the <strong>right not to be subject to a decision based solely on automated processing, including profiling, that produces legal or similarly significant effects</strong>, with narrow exceptions (contract necessity, law, explicit consent + safeguards). (<a href="https://gdpr-info.eu/art-22-gdpr/?utm_source=chatgpt.com">GDPR</a>)</p>



<p>Regulators interpret this to cover things like:</p>



<ul class="wp-block-list">
<li>Automated credit denials.</li>



<li>Automated rejection in hiring pipelines.</li>



<li>Algorithmic decisions that materially affect access to benefits, pricing, or services. (<a href="https://gdprlocal.com/automated-decision-making-gdpr/?utm_source=chatgpt.com">GDPR Local</a>)</li>
</ul>



<p>For a SaaS founder, that means:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>‚öôÔ∏è Your AI feature</th><th>GDPR view</th></tr></thead><tbody><tr><td><strong>‚ÄúSmart‚Äù lead scoring</strong> that just prioritizes which user gets contacted first</td><td>Usually ‚Äúprofiling,‚Äù but not always Article 22-level; still needs transparency and lawful basis.</td></tr><tr><td><strong>Automated loan approval/denial</strong> via your API</td><td>Classic Article 22 territory; your customer and possibly you must provide human review options, meaningful information about logic, and ways to contest the decision.</td></tr><tr><td><strong>AI hiring assistant</strong> that rejects candidates without human review</td><td>High-risk under both AI Act and GDPR Article 22; triggers DPIA, strong transparency, and human oversight requirements.</td></tr></tbody></table></figure>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="GDPR_AI_Act_together"></span>GDPR + AI Act together<span class="ez-toc-section-end"></span></h3>



<p>In Europe, you don‚Äôt pick one regime ‚Äì <strong>you stack them.</strong></p>



<ul class="wp-block-list">
<li>AI Act tells you <strong>what kind of AI you‚Äôre allowed to deploy and how</strong> (risk-based controls, transparency for GPAI, etc.). (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>



<li>GDPR tells you <strong>whether you‚Äôre allowed to process the input/output data the way you are</strong>, and what you must tell users.</li>
</ul>



<p>In practice that means:</p>



<ul class="wp-block-list">
<li><strong>Lawful basis</strong> for training and inference on personal data (often legitimate interests, sometimes consent or contract).</li>



<li><strong>Transparency</strong>: privacy notices that clearly mention AI profiling/ADM and the essentials of how it works. (<a href="https://gdprlocal.com/automated-decision-making-gdpr/?utm_source=chatgpt.com">GDPR Local</a>)</li>



<li><strong>DPIA</strong> for any high-risk use (credit, employment, health, youth, etc.).</li>



<li><strong>Data minimization &amp; retention</strong>: don‚Äôt keep prompts, logs, or features longer than needed for the specific purpose.</li>
</ul>



<p>If you architect your SaaS for <strong>EU-grade compliance</strong>, you‚Äôll be in much better shape when US enforcement catches up.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%87%BA%F0%9F%87%B8_US_Patchwork_FTC_State_Privacy_Laws_And_New_AI_Statutes"></span>üá∫üá∏ US Patchwork: FTC, State Privacy Laws And New AI Statutes<span class="ez-toc-section-end"></span></h2>



<p>The US does not yet have an ‚ÄúAI Act.‚Äù Instead, you‚Äôre dealing with a <strong>layer cake</strong>:</p>



<ul class="wp-block-list">
<li>Federal agencies (FTC, CFPB, EEOC, HUD, OCR, etc.) applying existing laws. (<a href="https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-states?utm_source=chatgpt.com">White &amp; Case</a>)</li>



<li>State-level privacy laws and AI-specific acts. (<a href="https://fpf.org/blog/the-state-of-state-ai-legislative-approaches-to-ai-in-2025/?utm_source=chatgpt.com">Future of Privacy Forum</a>)</li>



<li>NIST‚Äôs AI Risk Management Framework as the de facto governance playbook. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="FTC_%E2%80%9CNo_AI_exemption_from_the_laws_on_the_books%E2%80%9D"></span>FTC: ‚ÄúNo AI exemption from the laws on the books‚Äù<span class="ez-toc-section-end"></span></h3>



<p>The Federal Trade Commission has been very explicit: <strong>using AI doesn‚Äôt give you a free pass</strong> from consumer protection laws. (<a href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes?utm_source=chatgpt.com">Federal Trade Commission</a>)</p>



<p>Examples you can drop into your article:</p>



<ul class="wp-block-list">
<li><strong>Operation AI Comply</strong> ‚Äì an enforcement initiative targeting deceptive AI marketing, unsubstantiated performance claims, and unfair AI-related practices. (<a href="https://www.davispolk.com/insights/client-update/ftc-announces-new-enforcement-initiative-targeting-deceptive-ai-practices?utm_source=chatgpt.com">Davis Polk</a>)</li>



<li><strong>DoNotPay ‚Äúrobot lawyer‚Äù case</strong> ‚Äì FTC fined the company and barred them from making unsupported claims that their AI could replace lawyers or deliver legal services it had not been tested or trained for. (<a href="https://www.theverge.com/2024/9/25/24254405/federal-trade-commission-donotpay-robot-lawyers-artificial-intelligence-scams?utm_source=chatgpt.com">The Verge</a>)</li>
</ul>



<p>The message: if your SaaS advertises AI:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>üö´ Bad pattern</th><th>What the FTC sees</th></tr></thead><tbody><tr><td>‚ÄúOur AI is 99% accurate‚Äù with no robust testing</td><td><strong>Deceptive claim</strong> ‚Äì you need evidence before stating performance numbers.</td></tr><tr><td>‚ÄúAI lawyer,‚Äù ‚ÄúAI doctor,‚Äù ‚ÄúAI financial advisor‚Äù but no comparable oversight or qualification</td><td><strong>Misleading professional claims</strong>, especially if you strongly imply human-equivalent expertise.</td></tr><tr><td>Hiding the fact that outcomes are AI-generated or experimental</td><td><strong>Deception by omission</strong>; expect enforcement where users are materially misled.</td></tr></tbody></table></figure>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="State_AI_and_privacy_laws"></span>State AI and privacy laws<span class="ez-toc-section-end"></span></h3>



<p>States are rapidly filling the void:</p>



<ul class="wp-block-list">
<li><strong>Colorado Artificial Intelligence Act (SB24-205)</strong> ‚Äì first broad ‚Äúhigh-risk AI‚Äù law in the US, requiring developers and deployers of high-risk systems to exercise <strong>‚Äúreasonable care‚Äù</strong> to prevent algorithmic discrimination and to provide impact assessments and notices; implementation is being adjusted before it fully kicks in. (<a href="https://leg.colorado.gov/bills/sb24-205?utm_source=chatgpt.com">Colorado General Assembly</a>)</li>



<li><strong>Connecticut AI Transparency (SB1295)</strong> ‚Äì amends the Connecticut Data Privacy Act to require controllers to disclose in their privacy notices <strong>if they use personal data to train large language models</strong>. (<a href="https://ai-law-center.orrick.com/us-ai-law-tracker-see-all-states/?utm_source=chatgpt.com">ai-law-center.orrick.com</a>)</li>



<li><strong>Comprehensive state privacy laws</strong> (California, Colorado, Connecticut, Virginia, Utah, etc.) ‚Äì most now have explicit rules on profiling, targeted advertising, sensitive data, and data subject rights, with active rulemaking in 2025. (<a href="https://iapp.org/news/a/retrospective-2025-in-state-data-privacy-law?utm_source=chatgpt.com">IAPP</a>)</li>
</ul>



<p>State Attorneys General have also been using <strong>existing privacy and civil rights laws</strong> to go after AI misuse (bias in hiring, discriminatory scoring, deceptive ‚ÄúAI‚Äù marketing) even where no AI-specific statute exists. (<a href="https://www.reuters.com/legal/legalindustry/state-ags-fill-ai-regulatory-void-2025-05-19/?utm_source=chatgpt.com">Reuters</a>)</p>



<p>Layer on top of that the political fight over whether the federal government should preempt state AI laws entirely, and you have a dynamic, shifting patchwork. (<a href="https://www.politico.com/news/2025/11/19/white-house-prepares-executive-order-to-block-state-ai-laws-00660719?utm_source=chatgpt.com">Politico</a>)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%93%90_NIST_AI_Risk_Management_Framework_The_De_Facto_Backbone"></span>üìê NIST AI Risk Management Framework: The De Facto Backbone<span class="ez-toc-section-end"></span></h2>



<p>In the absence of a single US AI statute, regulators and state governments keep pointing back to <strong>NIST‚Äôs AI Risk Management Framework (AI RMF 1.0)</strong> as the blueprint for ‚Äútrustworthy AI.‚Äù</p>



<ul class="wp-block-list">
<li>Published by NIST in 2023, the AI RMF is <strong>voluntary guidance</strong> to help manage AI risks across the lifecycle: governance, mapping, measuring, and managing AI risk. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</li>



<li>Colorado‚Äôs own AI governance program specifically cites NIST AI RMF in how it approves and monitors state AI use-cases. (<a href="https://www.axios.com/local/denver/2025/11/13/colorado-ai-state-government?utm_source=chatgpt.com">Axios</a>)</li>
</ul>



<p>For SaaS, the RMF gives you a <strong>structure you can reuse</strong> in Europe, the US, and everywhere else:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>RMF function</th><th>What you‚Äôd actually implement inside a SaaS company</th></tr></thead><tbody><tr><td><strong>Govern</strong></td><td>Clear AI roles (product, security, legal), an AI policy, and board/leadership oversight of ‚Äúhigh-impact‚Äù AI features.</td></tr><tr><td><strong>Map</strong></td><td>Inventory of all AI/ML systems: what they do, what data they use, who is affected, and which laws might apply (AI Act, GDPR, FTC/state).</td></tr><tr><td><strong>Measure</strong></td><td>Regular testing for accuracy, bias, robustness, security posture, and monitoring for drift; documented test reports.</td></tr><tr><td><strong>Manage</strong></td><td>Mitigation plans (kill-switch, human override, escalation paths), incident response for AI failures, and user complaint/appeal channels.</td></tr></tbody></table></figure>



<p>Once you have that, aligning with AI Act ‚Äúhigh-risk‚Äù controls, GDPR DPIAs, and US AG expectations becomes <em>description and mapping work</em> rather than constant improvisation.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%AD_Crosswalk_What_You_Must_Actually_Do_By_Region"></span>üß≠ Crosswalk: What You Must Actually Do, By Region<span class="ez-toc-section-end"></span></h2>



<p>Here‚Äôs a founder-friendly crosswalk that you can pretty much turn into a visual widget.</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Compliance theme</th><th>EU (AI Act + GDPR)</th><th>US (FTC + state patchwork)</th><th>Strategy for global SaaS</th></tr></thead><tbody><tr><td><strong>System inventory</strong></td><td>Required implicitly to classify systems as high-risk and apply appropriate controls; DPIAs for risky processing. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td><td>Strongly recommended by NIST AI RMF; expected by regulators when things go wrong. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</td><td>Maintain a single <strong>AI system registry</strong> with purpose, data, risk level and jurisdictional tags.</td></tr><tr><td><strong>Risk classification</strong></td><td>You must know if you‚Äôre in <strong>unacceptable, high-risk, limited-risk, or minimal-risk</strong> buckets; Annex III is key for high-risk. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td><td>Colorado AI Act and similar bills also focus on ‚Äúhigh-risk‚Äù systems (e.g., affecting employment, credit, services). (<a href="https://leg.colorado.gov/bills/sb24-205?utm_source=chatgpt.com">Colorado General Assembly</a>)</td><td>Reuse AI Act classification internally and then tag where extra US rules (CO, CT, sectoral) might also kick in.</td></tr><tr><td><strong>Automated decisions about people</strong></td><td>Article 22 GDPR and similar rules restrict <strong>solely automated decisions with legal/similar significant effects</strong>; require human review and transparency. (<a href="https://gdpr-info.eu/art-22-gdpr/?utm_source=chatgpt.com">GDPR</a>)</td><td>No single ADM statute, but civil-rights, credit, employment and consumer laws give regulators tools to attack discriminatory or opaque ADM. (<a href="https://www.reuters.com/legal/legalindustry/state-ags-fill-ai-regulatory-void-2025-05-19/?utm_source=chatgpt.com">Reuters</a>)</td><td>Treat consequential ADM as ‚Äúhot zone‚Äù globally: build <strong>human-in-the-loop + explanation + appeal</strong> by design.</td></tr><tr><td><strong>Data protection &amp; privacy</strong></td><td>GDPR (and UK GDPR) set the gold standard: lawful basis, minimization, DPIA, rights, retention limits, etc. (<a href="https://gdprlocal.com/automated-decision-making-gdpr/?utm_source=chatgpt.com">GDPR Local</a>)</td><td>State privacy laws (CCPA/CPRA, ColoPA, etc.) require notices, opt-outs, and special care around sensitive data &amp; profiling. (<a href="https://iapp.org/news/a/retrospective-2025-in-state-data-privacy-law?utm_source=chatgpt.com">IAPP</a>)</td><td>Use GDPR-grade data governance as baseline, then layer state-specific disclosures (e.g., using data to train LLMs under CT SB1295). (<a href="https://ai-law-center.orrick.com/us-ai-law-tracker-see-all-states/?utm_source=chatgpt.com">ai-law-center.orrick.com</a>)</td></tr><tr><td><strong>Marketing &amp; claims about AI</strong></td><td>AI Act adds transparency duties for certain AI interactions; unfair commercial practices law still applies. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td><td>FTC has made it explicit there is <strong>no AI exemption</strong> from deceptive-practices rules; Operation AI Comply shows they will act. (<a href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes?utm_source=chatgpt.com">Federal Trade Commission</a>)</td><td>Treat AI claims like clinical claims: substantiate accuracy and benefits; avoid ‚Äúrobot lawyer/doctor‚Äù hype; clearly label AI-generated interactions.</td></tr><tr><td><strong>Governance &amp; documentation</strong></td><td>AI Act and GDPR both expect <strong>traceable documentation</strong>: technical docs, DPIAs, logs, policies. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td><td>NIST AI RMF + regulator expectations mean you should have <strong>policies, risk assessments, test records</strong> ready to show. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</td><td>Build one documentation spine (AI RMF-style) and then generate per-region annexes (e.g., AI Act technical file, GDPR DPIA, Colorado high-risk assessment).</td></tr></tbody></table></figure>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%9B%A0_Implementation_Roadmap_For_SaaS_Founders"></span>üõ† Implementation Roadmap For SaaS Founders<span class="ez-toc-section-end"></span></h2>



<p>If you don‚Äôt have a full compliance team, think in phases rather than perfection.</p>



<p><strong>Phase 1 ‚Äì Map and triage</strong></p>



<ul class="wp-block-list">
<li>Build a <strong>simple AI system inventory</strong>: what features, what data, what decisions, which customers (EU/US/elsewhere).</li>



<li>Tag anything that touches <strong>credit, employment, education, health, essential services, or youth</strong> as high-priority for legal review.</li>
</ul>



<p><strong>Phase 2 ‚Äì Governance and guardrails</strong></p>



<ul class="wp-block-list">
<li>Adopt a lightweight <strong>NIST AI RMF-inspired policy</strong>: who approves new AI features, how risks are assessed, where logs and tests live. (<a href="https://www.nist.gov/itl/ai-risk-management-framework?utm_source=chatgpt.com">NIST</a>)</li>



<li>Establish bright-line rules:
<ul class="wp-block-list">
<li>No solely automated consequential decisions without human override.</li>



<li>No AI marketing claims without documented testing.</li>



<li>No training on customer data unless contracts and privacy notices clearly permit it.</li>
</ul>
</li>
</ul>



<p><strong>Phase 3 ‚Äì Region-specific overlays</strong></p>



<ul class="wp-block-list">
<li>For <strong>EU/UK</strong> customers: do DPIAs for high-impact use-cases, build AI Act classification into product design, and prepare to treat certain products as <strong>high-risk AI systems</strong>. (<a href="https://artificialintelligenceact.eu/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>



<li>For <strong>US</strong>: align privacy practices with the strictest state laws you touch; monitor Colorado and Connecticut AI developments; and treat FTC guidance like it‚Äôs already codified. (<a href="https://leg.colorado.gov/bills/sb24-205?utm_source=chatgpt.com">Colorado General Assembly</a>)</li>
</ul>



<p>If you do that, you won‚Äôt just be ‚Äútechnically compliant‚Äù ‚Äì you‚Äôll look like the rare SaaS company that actually <strong>knows where it is on the AI map</strong>, which is increasingly a selling point with large customers and regulators alike.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<ul class="wp-block-list">
<li><a href="https://www.reuters.com/legal/legalindustry/state-ags-fill-ai-regulatory-void-2025-05-19/?utm_source=chatgpt.com">Reuters</a></li>



<li><a href="https://www.axios.com/local/denver/2025/11/13/colorado-ai-state-government?utm_source=chatgpt.com">Axios</a></li>



<li><a href="https://www.theverge.com/2024/9/25/24254405/federal-trade-commission-donotpay-robot-lawyers-artificial-intelligence-scams?utm_source=chatgpt.com">The Verge</a></li>



<li><a href="https://www.politico.com/news/2025/11/19/white-house-prepares-executive-order-to-block-state-ai-laws-00660719?utm_source=chatgpt.com">Politico</a></li>
</ul>
</div>
    </article>
  </main>

  <footer><p>¬© Terms.Law. All rights reserved.</p></footer>
</body>
</html>