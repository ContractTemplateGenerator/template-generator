<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-901N2Y3CDZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-901N2Y3CDZ');
    </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Automated decision-making and explainability: what you owe users when AI denies them something | Terms.Law</title>
  <meta name="description" content="The document discusses the legal obligations related to automated decision-making in high-stakes scenarios such as loans, hiring, and benefits. It outlines righ">
  <link rel="canonical" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/shared/styles.css">
</head>
<body>
  <div id="site-header"></div>
  <script src="/shared/header-loader.js"></script>

  <main>
    <article>
      <h1>Automated decision-making and explainability: what you owe users when AI denies them something</h1>
      <div class="meta">Published: December 5, 2025 â€¢ AI</div>
      <div class="content">
<p>When an AI system silently decides â€œnoâ€ on a loan, job, apartment, or benefit, thatâ€™s no longer just a product choice. In 2025, itâ€™s squarely in the sights of <strong>data protection, financial, civil-rights, and new AI-specific laws</strong>.</p>



<p>This guide focuses on what you <em>actually</em> owe users when an automated system denies them something important â€“ and what a legally defensible explanation looks like.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div id="ez-toc-container" class="ez-toc-v2_0_79_2 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction">
<div class="ez-toc-title-container">
<p class="ez-toc-title" style="cursor:inherit">Contents</p>
<span class="ez-toc-title-toggle"><a href="#" class="ez-toc-pull-right ez-toc-btn ez-toc-btn-xs ez-toc-btn-default ez-toc-toggle" aria-label="Toggle Table of Content"><span class="ez-toc-js-icon-con"><span class=""><span class="eztoc-hide" style="display:none;">Toggle</span><span class="ez-toc-icon-toggle-span"><svg style="fill: #999;color:#999" xmlns="http://www.w3.org/2000/svg" class="list-377408" width="20px" height="20px" viewBox="0 0 24 24" fill="none"><path d="M6 6H4v2h2V6zm14 0H8v2h12V6zM4 11h2v2H4v-2zm16 0H8v2h12v-2zM4 16h2v2H4v-2zm16 0H8v2h12v-2z" fill="currentColor"></path></svg><svg style="fill: #999;color:#999" class="arrow-unsorted-368013" xmlns="http://www.w3.org/2000/svg" width="10px" height="10px" viewBox="0 0 24 24" version="1.2" baseProfile="tiny"><path d="M18.2 9.3l-6.2-6.3-6.2 6.3c-.2.2-.3.4-.3.7s.1.5.3.7c.2.2.4.3.7.3h11c.3 0 .5-.1.7-.3.2-.2.3-.5.3-.7s-.1-.5-.3-.7zM5.8 14.7l6.2 6.3 6.2-6.3c.2-.2.3-.5.3-.7s-.1-.5-.3-.7c-.2-.2-.4-.3-.7-.3h-11c-.3 0-.5.1-.7.3-.2.2-.3.5-.3.7s.1.5.3.7z"/></svg></span></span></span></a></span></div>
<nav><ul class='ez-toc-list ez-toc-list-level-1 ' ><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-1" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%9A%A6_When_an_AI_decision_triggers_legal_duties" >ğŸš¦ When an AI decision triggers legal duties</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-2" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Quick_map_of_%E2%80%9Cdenials%E2%80%9D_that_raise_the_bar" >Quick map of â€œdenialsâ€ that raise the bar</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-3" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%A7%A0_What_counts_as_%E2%80%9Cautomated_decision-making%E2%80%9D" >ğŸ§  What counts as â€œautomated decision-makingâ€?</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-4" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%93%9C_What_you_owe_users_under_GDPR_and_UK_GDPR" >ğŸ“œ What you owe users under GDPR and UK GDPR</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-5" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#What_that_looks_like_in_user-facing_terms" >What that looks like in user-facing terms</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-6" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%8F%9B_EU_AI_Act_overlay_high-risk_AI_must_be_explainable_in_practice" >ğŸ› EU AI Act overlay: high-risk AI must be explainable in practice</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-7" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%87%BA%F0%9F%87%B8_US_adverse_action_civil-rights_law_and_state_AI_acts" >ğŸ‡ºğŸ‡¸ US: adverse action, civil-rights law, and state AI acts</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-8" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Credit_lending_ECOA_FCRA_adverse_action" >Credit &amp; lending: ECOA + FCRA adverse action</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-9" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Employment_housing_and_discrimination" >Employment, housing and discrimination</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-10" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#State_AI_laws_Colorado_Connecticut_and_others" >State AI laws: Colorado, Connecticut and others</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-11" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%94%8D_Model_explainability_vs_user-facing_explanations" >ğŸ” Model explainability vs user-facing explanations</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-12" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%A7%AD_Red_yellow_green_patterns_for_denials" >ğŸ§­ Red / yellow / green patterns for denials</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-13" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Red_clearly_non-compliant_patterns" >Red: clearly non-compliant patterns</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-14" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Yellow_legally_possible_but_fragile" >Yellow: legally possible, but fragile</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-15" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#Green_strong_defensible_pattern" >Green: strong, defensible pattern</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-16" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%9B%A0_Implementation_playbook_for_organisations_using_ADM" >ğŸ›  Implementation playbook for organisations using ADM</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-17" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#1_Catalogue_consequential_AI_decisions" >1. Catalogue consequential AI decisions</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-18" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#2_Decide_where_you_will_not_allow_purely_automated_denials" >2. Decide where you will not allow purely automated denials</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-19" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#3_Build_an_%E2%80%9Cexplanation_generator%E2%80%9D_layer" >3. Build an â€œexplanation generatorâ€ layer</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-20" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#4_Stand_up_a_rights_appeals_channel" >4. Stand up a rights &amp; appeals channel</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-21" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#5_Align_with_a_governance_framework" >5. Align with a governance framework</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-22" href="https://terms.law/2025/12/05/automated-decision-making-and-explainability-what-you-owe-users-when-ai-denies-them-something/#%F0%9F%93%8C_Bottom_line" >ğŸ“Œ Bottom line</a></li></ul></nav></div>
<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%9A%A6_When_an_AI_decision_triggers_legal_duties"></span>ğŸš¦ When an AI decision triggers legal duties<span class="ez-toc-section-end"></span></h2>



<p>Across regimes, the â€œhot zoneâ€ is <strong>consequential, people-affecting decisions</strong>, especially when they are <em>solely</em> or <em>predominantly</em> automated:</p>



<ul class="wp-block-list">
<li>Credit approvals and credit limit changes</li>



<li>Housing and insurance</li>



<li>Job screening, hiring, promotion, firing</li>



<li>Access to education, healthcare, public benefits</li>



<li>Other â€œlegal or similarly significantâ€ effects</li>
</ul>



<p>Under <strong>GDPR/UK GDPR</strong>, Article 22 restricts solely automated decisions that produce legal or similarly significant effects (classic examples: automatic refusal of an online credit application or e-recruitment that automatically filters out candidates).(<a href="https://gdpr-info.eu/art-22-gdpr/?utm_source=chatgpt.com">GDPR</a>)</p>



<p>In the US, sector laws like <strong>ECOA/Reg B, FCRA, fair housing/employment statutes, and now state AI acts (Colorado, Connecticut, etc.)</strong> kick in when automated systems are used to make or heavily influence such consequential decisions.(<a href="https://www.skadden.com/insights/publications/2024/01/cfpb-applies-adverse-action-notification-requirement?utm_source=chatgpt.com">Skadden</a>)</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Quick_map_of_%E2%80%9Cdenials%E2%80%9D_that_raise_the_bar"></span>Quick map of â€œdenialsâ€ that raise the bar<span class="ez-toc-section-end"></span></h3>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>If your AIâ€¦</th><th>Typical example</th><th>Legal lens</th></tr></thead><tbody><tr><td><strong>Denies money or changes financial terms</strong></td><td>Credit denial, lower credit limit, worse loan pricing</td><td>ECOA/Reg B + FCRA adverse action duties (US), GDPR + AI Act â€œhigh-riskâ€ decision (EU), state AI acts like Colorado for â€œconsequentialâ€ decisions. (<a href="https://www.skadden.com/insights/publications/2024/01/cfpb-applies-adverse-action-notification-requirement?utm_source=chatgpt.com">Skadden</a>)</td></tr><tr><td><strong>Rejects or filters a job candidate / promotion</strong></td><td>Automated CV screening, scored video interviews</td><td>GDPR Art 22 &amp; DPIAs (EU/UK); EEOC, Title VII, ADA in US; Colorado/Connecticut AI rules for high-risk employment systems. (<a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/automated-decision-making-and-profiling/what-does-the-uk-gdpr-say-about-automated-decision-making-and-profiling/?utm_source=chatgpt.com">ICO</a>)</td></tr><tr><td><strong>Blocks access to housing, insurance, education or benefits</strong></td><td>Scoring tools for rental applications, health insurance underwriting, school admissions, public benefits</td><td>AI Act â€œhigh-riskâ€ categories, GDPR Art 22; US fair housing/benefits laws; Colorado â€œconsequential decisionâ€ protections. (<a href="https://artificialintelligenceact.eu/article/6/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</td></tr></tbody></table></figure>



<p>Whenever youâ€™re in this zone, you should assume: <strong>the user is entitled to more than just â€œweâ€™re sorry, you were not selected.â€</strong></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%A0_What_counts_as_%E2%80%9Cautomated_decision-making%E2%80%9D"></span>ğŸ§  What counts as â€œautomated decision-makingâ€?<span class="ez-toc-section-end"></span></h2>



<p>Most laws distinguish between:</p>



<ul class="wp-block-list">
<li><strong>Solely automated decisions</strong> â€“ no meaningful human involvement; the systemâ€™s output is effectively final.</li>



<li><strong>Human-in-the-loop decisions</strong> â€“ humans can meaningfully review and override the automated recommendation.</li>
</ul>



<p>Under GDPR/UK GDPR, Article 22 applies only where the decision is <strong>entirely automated</strong> and has legal/similarly significant effects.(<a href="https://gdpr-info.eu/art-22-gdpr/?utm_source=chatgpt.com">GDPR</a>)</p>



<p>Guidance from regulators (e.g., ICO &amp; The Alan Turing Institute) stresses that â€œmeaningful human involvementâ€ isnâ€™t a rubber stamp; the human needs real authority, time, and information to challenge the modelâ€™s output.(<a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/?utm_source=chatgpt.com">ICO</a>)</p>



<p><strong>Practical rule of thumb:</strong> if your staff are <em>usually</em> just clicking â€œapproveâ€ on whatever the model says, regulators will treat the outcome as effectively automated.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%93%9C_What_you_owe_users_under_GDPR_and_UK_GDPR"></span>ğŸ“œ What you owe users under GDPR and UK GDPR<span class="ez-toc-section-end"></span></h2>



<p>Under EU/UK law, when an AI system makes (or heavily shapes) a consequential decision about a person, you typically owe them:</p>



<ol class="wp-block-list">
<li><strong>Notice that an automated decision is being made</strong></li>



<li><strong>The right not to be subject to solely automated decisions with significant effects</strong>, subject to limited exceptions</li>



<li><strong>Meaningful information about the logic involved</strong></li>



<li><strong>Information about the significance and envisaged consequences for them</strong></li>



<li><strong>The right to obtain human intervention, express their view, and contest the decision</strong>(<a href="https://gdpr-info.eu/art-22-gdpr/?utm_source=chatgpt.com">GDPR</a>)</li>
</ol>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="What_that_looks_like_in_user-facing_terms"></span>What that looks like in user-facing terms<span class="ez-toc-section-end"></span></h3>



<p>The ICO/Turing guidance breaks â€œexplainabilityâ€ down into flavours (rationale, data, fairness, safety, impact).(<a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/?utm_source=chatgpt.com">ICO</a>)</p>



<p>You can translate that into a concrete explanation template:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Element</th><th>Question in the userâ€™s head</th><th>What your explanation should cover</th></tr></thead><tbody><tr><td><strong>Rationale</strong></td><td><em>â€œWhy was I denied?â€</em></td><td>The main factors that drove the decision (e.g., short credit history + high utilization), in plain language.</td></tr><tr><td><strong>Process</strong></td><td><em>â€œHow does this system decide generally?â€</em></td><td>A high-level description of how the model works (e.g., â€œWe evaluate several factors from your application and credit file to estimate ability to repayâ€).</td></tr><tr><td><strong>Data</strong></td><td><em>â€œWhat data about me did you use?â€</em></td><td>Data sources (application, credit bureau, internal behavior data), with emphasis on which inputs mattered most.</td></tr><tr><td><strong>Fairness</strong></td><td><em>â€œWas I treated fairly?â€</em></td><td>A statement on how the system is tested for bias and what protections exist (e.g. protected characteristics are not used directly, ongoing bias checks).</td></tr><tr><td><strong>Control</strong></td><td><em>â€œWhat can I do now?â€</em></td><td>Next steps: how to get human review, how to correct data, and when/if they can reapply.</td></tr></tbody></table></figure>



<p>You donâ€™t have to open-source your model weights, but <strong>you do have to make the decision understandable to a non-engineer</strong>.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%8F%9B_EU_AI_Act_overlay_high-risk_AI_must_be_explainable_in_practice"></span>ğŸ› EU AI Act overlay: high-risk AI must be explainable in practice<span class="ez-toc-section-end"></span></h2>



<p>The <strong>EU AI Act</strong> adds AI-specific duties on top of GDPR:</p>



<ul class="wp-block-list">
<li>It classifies many of these consequential use-cases (credit, employment, education, essential services) as <strong>â€œhigh-risk AI systemsâ€</strong>.(<a href="https://artificialintelligenceact.eu/article/6/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>



<li>Providers of such systems must implement <strong>risk management, data governance, logging, transparency, and human oversight</strong> before entering the EU market.(<a href="https://artificialintelligenceact.eu/high-level-summary/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>
</ul>



<p>For people on the receiving end, the AI Act expects, in substance:</p>



<ul class="wp-block-list">
<li>Clear <strong>user-facing notices</strong> that they are subject to a high-risk AI system</li>



<li>Plain language information about the systemâ€™s <strong>purpose, main parameters, and limitations</strong></li>



<li>The ability to <strong>challenge or seek human review</strong> when the system denies something important</li>
</ul>



<p>The Commissionâ€™s emerging code of practice and systemic-risk guidance emphasise transparent documentation, model evaluations, and clear communication of risks and capabilities.(<a href="https://www.reuters.com/business/eu-code-practice-help-firms-with-ai-rules-will-focus-copyright-safety-2025-07-10/?utm_source=chatgpt.com">Reuters</a>)</p>



<p>In other words: if your AI is making high-stakes calls in the EU, you need to be able to <strong>explain and defend both the decision and the system behind it.</strong></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%87%BA%F0%9F%87%B8_US_adverse_action_civil-rights_law_and_state_AI_acts"></span>ğŸ‡ºğŸ‡¸ US: adverse action, civil-rights law, and state AI acts<span class="ez-toc-section-end"></span></h2>



<p>The US doesnâ€™t have a single â€œArticle 22â€, but it does have <strong>sector rules with teeth</strong> and a growing state-level AI framework.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Credit_lending_ECOA_FCRA_adverse_action"></span>Credit &amp; lending: ECOA + FCRA adverse action<span class="ez-toc-section-end"></span></h3>



<p>If your system denies or worsens credit, <strong>ECOA and Regulation B</strong> require a written <strong>adverse action notice</strong> with <strong>â€œspecific reasons for the action taken.â€</strong>(<a href="https://www.skadden.com/insights/publications/2024/01/cfpb-applies-adverse-action-notification-requirement?utm_source=chatgpt.com">Skadden</a>)</p>



<p>Key CFPB guidance points:</p>



<ul class="wp-block-list">
<li>You <strong>canâ€™t hide behind AI</strong> â€“ lenders must give specific and accurate reasons, even when using complex or opaque models.</li>



<li>Generic explanations like â€œyour score was too lowâ€ or â€œyou didnâ€™t meet our internal criteriaâ€ are <strong>not sufficient</strong>.</li>



<li>When FCRA credit scores are used, you must disclose the score and the <em>key factors</em> that adversely affected it.(<a href="https://files.consumerfinance.gov/f/documents/cfpb_adverse_action_notice_circular_2023-09.pdf?utm_source=chatgpt.com">Consumer Financial Protection Bureau</a>)</li>
</ul>



<p>So if an ML underwriting model denies a user, a compliant notice looks more like:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>â€œWe declined your application because: (1) Your total monthly debt payments are high relative to your income; (2) You have had two recent delinquencies; and (3) Your revolving credit utilization is high.â€</p>
</blockquote>



<p>â€¦not â€œthe AI model said you are too risky.â€</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Employment_housing_and_discrimination"></span>Employment, housing and discrimination<span class="ez-toc-section-end"></span></h3>



<p>A joint statement by <strong>FTC, DOJ, CFPB and EEOC</strong> makes clear that existing civil-rights and consumer-protection statutes fully apply to AI-driven decisions, including:(<a href="https://www.ftc.gov/system/files/ftc_gov/pdf/EEOC-CRT-FTC-CFPB-AI-Joint-Statement%28final%29.pdf?utm_source=chatgpt.com">Federal Trade Commission</a>)</p>



<ul class="wp-block-list">
<li>Title VII in hiring, promotion, firing</li>



<li>Fair housing and credit laws</li>



<li>Disability discrimination rules</li>



<li>FTC Act Â§5 (unfair/deceptive practices)</li>
</ul>



<p>If an automated hiring or housing system screens someone out, they are often entitled â€“ as a practical matter if not always by explicit statute â€“ to:</p>



<ul class="wp-block-list">
<li><strong>Notice</strong> that automated tools were used</li>



<li><strong>Information about relevant criteria</strong> used to evaluate them</li>



<li><strong>A channel to request reconsideration or human review</strong>, especially where discrimination or error is alleged</li>
</ul>



<p>Regulators increasingly expect that <strong>explanations be good enough to let the person spot potential discrimination or mistakes</strong>.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="State_AI_laws_Colorado_Connecticut_and_others"></span>State AI laws: Colorado, Connecticut and others<span class="ez-toc-section-end"></span></h3>



<p>States are now codifying explicit rights in AI-mediated decisions.</p>



<p><strong>Colorado Artificial Intelligence Act (SB24-205)</strong> (effective 2026) focuses on <strong>high-risk AI systems</strong> making â€œconsequential decisionsâ€ (lending, employment, education, housing, healthcare, insurance, essential services). It requires deployers to:(<a href="https://www.naag.org/attorney-general-journal/a-deep-dive-into-colorados-artificial-intelligence-act/?utm_source=chatgpt.com">naag.org</a>)</p>



<ul class="wp-block-list">
<li>Notify consumers when high-risk AI is used to make a consequential decision</li>



<li>Provide <strong>an explanation</strong> of any adverse consequential decision, including the main data and reasons</li>



<li>Offer the right to <strong>correct information</strong> and <strong>appeal for human review</strong></li>



<li>Maintain risk management programs and impact assessments aligned with frameworks like NIST AI RMF</li>
</ul>



<p>Connecticutâ€™s <strong>SB 2</strong> similarly requires notice before high-risk AI is used for consequential decisions, and gives individuals the right to an explanation, data correction, and human appeal after an adverse AI-driven decision.(<a href="https://fpf.org/blog/setting-the-stage-connecticut-senate-bill-2-lays-the-groundwork-for-responsible-ai-in-the-states/?utm_source=chatgpt.com">Future of Privacy Forum</a>)</p>



<p>So in many US jurisdictions, <strong>â€œAI said noâ€ without a reason + a way to contest</strong> is moving from bad practice to potentially unlawful.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%94%8D_Model_explainability_vs_user-facing_explanations"></span>ğŸ” Model explainability vs user-facing explanations<span class="ez-toc-section-end"></span></h2>



<p>Engineers think of explainability in terms of <strong>feature importance, SHAP values, partial dependence plots</strong>.</p>



<p>Regulators and users, by contrast, care about something much simpler:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><strong>â€œWhat were the main reasons <em>in my case</em>, and what can I do about it?â€</strong></p>
</blockquote>



<p>Hereâ€™s how to bridge those worlds:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Internal (data science)</th><th>Translated user-facing explanation</th></tr></thead><tbody><tr><td>Top features: <code>DTI_ratio</code>, <code>recent_delinquency_count</code>, <code>revolving_utilization</code></td><td>â€œWe used information from your application and credit history. In your case, the key reasons were: (1) your debt payments are high relative to income; (2) two late payments in the past 6 months; and (3) high use of your available credit lines.â€</td></tr><tr><td>SHAP global bias checks</td><td>â€œWe regularly test this system to reduce the risk of unfair treatment and do not use protected characteristics, such as race, gender, or religion, as inputs.â€</td></tr><tr><td>Confidence intervals, model uncertainty</td><td>â€œBased on the information we currently have, weâ€™re not confident that the loan can be repaid on the requested terms. If your circumstances change or you can provide updated information, you may reapply.â€</td></tr></tbody></table></figure>



<p>The laws do <strong>not</strong> require you to hand over raw feature importance charts â€“ they require you to give users <strong>specific, accurate, understandable reasons</strong>.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%AD_Red_yellow_green_patterns_for_denials"></span>ğŸ§­ Red / yellow / green patterns for denials<span class="ez-toc-section-end"></span></h2>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Red_clearly_non-compliant_patterns"></span>Red: clearly non-compliant patterns<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>No explanation at all: â€œYour application was not approved. Decisions are final.â€</li>



<li>Vague pseudo-explanations: â€œYou did not meet our internal criteriaâ€ / â€œInsufficient AI scoreâ€</li>



<li>No way to contact a human, correct data, or appeal</li>



<li>Silence about the fact that AI or automated scoring was used</li>
</ul>



<p>These raise immediate red flags under <strong>ECOA/FCRA for credit</strong>, <strong>GDPR/Art 22</strong>, and <strong>state AI/consumer laws</strong>.(<a href="https://www.skadden.com/insights/publications/2024/01/cfpb-applies-adverse-action-notification-requirement?utm_source=chatgpt.com">Skadden</a>)</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Yellow_legally_possible_but_fragile"></span>Yellow: legally possible, but fragile<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>Explanation mentions some factors but is generic or boilerplate</li>



<li>Human review technically exists, but is hard to access or slow</li>



<li>AI use is disclosed in a privacy policy, but not at the point of decision</li>
</ul>



<p>These can be defensible if backed by good documentation, but youâ€™ll be in a weak position if a regulator or court scrutinizes your practice.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Green_strong_defensible_pattern"></span>Green: strong, defensible pattern<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>Decision screen and/or notice clearly states <strong>what was decided</strong>, <strong>that an automated system was used</strong>, and <strong>the main reasons</strong></li>



<li>Notice explains <strong>what data sources were used</strong> and how the user can <strong>correct errors</strong></li>



<li>Obvious path to <strong>request human review</strong>, with reasonable turnaround</li>



<li>Internal logs showing how the AI decision was made and which features mattered</li>
</ul>



<p>This is the pattern that lines up with <strong>GDPR, AI Act high-risk duties, ECOA/FCRA adverse action, and state AI acts like Colorado and Connecticut.</strong>(<a href="https://gdprlocal.com/automated-decision-making-gdpr/?utm_source=chatgpt.com">GDPR Local</a>)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%9B%A0_Implementation_playbook_for_organisations_using_ADM"></span>ğŸ›  Implementation playbook for organisations using ADM<span class="ez-toc-section-end"></span></h2>



<p>If youâ€™re building or deploying AI that can deny people something important, you want an internal setup that looks sensible if printed out in front of a regulator.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="1_Catalogue_consequential_AI_decisions"></span>1. Catalogue consequential AI decisions<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>Maintain an <strong>inventory of all AI/ML systems</strong> that touch lending, jobs, housing, insurance, benefits, or other â€œlife-chanceâ€ areas.</li>



<li>Flag whether decisions are <strong>solely automated, human-in-the-loop, or human-only</strong>.</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="2_Decide_where_you_will_not_allow_purely_automated_denials"></span>2. Decide where you <em>will not</em> allow purely automated denials<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>For high-stakes contexts, default to <strong>human-in-the-loop</strong>, not fully automated, unless you can justify it under applicable law.</li>



<li>Document why human review is effective (staff training, authority, SLA for appeals).</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="3_Build_an_%E2%80%9Cexplanation_generator%E2%80%9D_layer"></span>3. Build an â€œexplanation generatorâ€ layer<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>For each model, define a <strong>short list of human-readable factors</strong> youâ€™re comfortable disclosing.</li>



<li>Wire explanations to your adverse decision notices / rejection emails, so reasons are consistent and logged.</li>



<li>Spot-check that explanations are <strong>specific and accurate</strong>, not generic boilerplate â€“ especially for credit denials.(<a href="https://files.consumerfinance.gov/f/documents/cfpb_adverse_action_notice_circular_2023-09.pdf?utm_source=chatgpt.com">Consumer Financial Protection Bureau</a>)</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="4_Stand_up_a_rights_appeals_channel"></span>4. Stand up a rights &amp; appeals channel<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>Provide a <strong>simple way to reach a person</strong> about automated decisions (web form, email, phone).</li>



<li>Define internal SLAs for:
<ul class="wp-block-list">
<li>Reviewing contested decisions</li>



<li>Correcting data</li>



<li>Re-running decisions under corrected data</li>
</ul>
</li>



<li>Keep records of appeals and outcomes for auditing and bias monitoring.</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="5_Align_with_a_governance_framework"></span>5. Align with a governance framework<span class="ez-toc-section-end"></span></h3>



<p>Frameworks like <strong>NIST AI RMF</strong> are increasingly referenced in both EU and US contexts as the standard for â€œreasonableâ€ AI risk management.(<a href="https://gdprlocal.com/ai-regulations-in-the-us/?utm_source=chatgpt.com">GDPR Local</a>)</p>



<p>Use them to anchor:</p>



<ul class="wp-block-list">
<li>Risk assessments (especially for high-risk/consequential systems)</li>



<li>Testing for accuracy, bias, robustness</li>



<li>Documentation that can double as your <strong>AI Act technical file, GDPR DPIA, and Colorado/Connecticut impact assessments</strong></li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%93%8C_Bottom_line"></span>ğŸ“Œ Bottom line<span class="ez-toc-section-end"></span></h2>



<p>When AI denies someone a loan, job, apartment, or benefit, you donâ€™t just owe them a clean UI. You owe them:</p>



<ul class="wp-block-list">
<li><strong>Advance notice</strong> that automation is in play</li>



<li><strong>Clear, specific reasons</strong> tailored to their situation</li>



<li><strong>A way to correct errors and get human review</strong></li>



<li>Evidence that youâ€™ve thought about and mitigated discrimination and unfairness</li>
</ul>



<p>The technology may be complex. The legal expectation is not:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><strong>If youâ€™re going to let AI say â€œnoâ€ to people in high-stakes situations, you must be able to look them in the eye â€“ and a regulator over your shoulder â€“ and explain why.</strong></p>
</blockquote>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<ul class="wp-block-list">
<li><a href="https://www.reuters.com/sustainability/boards-policy-regulation/ai-models-with-systemic-risks-given-pointers-how-comply-with-eu-ai-rules-2025-07-18/?utm_source=chatgpt.com">Reuters</a></li>



<li><a href="https://www.reuters.com/sustainability/boards-policy-regulation/how-eu-plans-ease-rules-big-tech-2025-11-19/?utm_source=chatgpt.com">Reuters</a></li>



<li><a href="https://www.theguardian.com/world/2025/nov/07/european-commission-ai-artificial-intelligence-act-trump-administration-tech-business?utm_source=chatgpt.com">The Guardian</a></li>
</ul>
</div>
    </article>
  </main>

  <footer><p>Â© 2025 Terms.Law. All rights reserved.</p></footer>
</body>
</html>