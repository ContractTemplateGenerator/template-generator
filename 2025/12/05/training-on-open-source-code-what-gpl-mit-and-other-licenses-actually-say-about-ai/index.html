<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Training on open source code: what GPL, MIT and other licenses actually say about AI | Terms.Law</title>
  <meta name="description" content="The post discusses the legal complexities surrounding AI training on open-source code, particularly under various licenses like GPL, MIT, and Apache. It highlig">
  <link rel="canonical" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/shared/styles.css">
</head>
<body>
  <div id="site-header"></div>
  <script src="/shared/header-loader.js"></script>

  <main>
    <article>
      <h1>Training on open source code: what GPL, MIT and other licenses actually say about AI</h1>
      <div class="meta">Published: December 5, 2025 â€¢ AI</div>
      <div class="content">
<p>ğŸ§  <em>If my model trains on GitHub, am I now â€œinfectedâ€ by GPL?</em><br>Thatâ€™s the question everyone from solo devs to Big Tech GCâ€™s has been wrestling with since Copilot and code copilots arrived.</p>



<p>This guide walks through how the main open-source licenses (MIT/BSD, Apache 2.0, GPL/LGPL, MPL, AGPL) intersect with AI training â€“ what the licenses actually say, what courts and community bodies (OSI, FSF, etc.) are doing with that, and where the real risk lives today. </p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div id="ez-toc-container" class="ez-toc-v2_0_79_2 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction">
<div class="ez-toc-title-container">
<p class="ez-toc-title" style="cursor:inherit">Contents</p>
<span class="ez-toc-title-toggle"><a href="#" class="ez-toc-pull-right ez-toc-btn ez-toc-btn-xs ez-toc-btn-default ez-toc-toggle" aria-label="Toggle Table of Content"><span class="ez-toc-js-icon-con"><span class=""><span class="eztoc-hide" style="display:none;">Toggle</span><span class="ez-toc-icon-toggle-span"><svg style="fill: #999;color:#999" xmlns="http://www.w3.org/2000/svg" class="list-377408" width="20px" height="20px" viewBox="0 0 24 24" fill="none"><path d="M6 6H4v2h2V6zm14 0H8v2h12V6zM4 11h2v2H4v-2zm16 0H8v2h12v-2zM4 16h2v2H4v-2zm16 0H8v2h12v-2z" fill="currentColor"></path></svg><svg style="fill: #999;color:#999" class="arrow-unsorted-368013" xmlns="http://www.w3.org/2000/svg" width="10px" height="10px" viewBox="0 0 24 24" version="1.2" baseProfile="tiny"><path d="M18.2 9.3l-6.2-6.3-6.2 6.3c-.2.2-.3.4-.3.7s.1.5.3.7c.2.2.4.3.7.3h11c.3 0 .5-.1.7-.3.2-.2.3-.5.3-.7s-.1-.5-.3-.7zM5.8 14.7l6.2 6.3 6.2-6.3c.2-.2.3-.5.3-.7s-.1-.5-.3-.7c-.2-.2-.4-.3-.7-.3h-11c-.3 0-.5.1-.7.3-.2.2-.3.5-.3.7s.1.5.3.7z"/></svg></span></span></span></a></span></div>
<nav><ul class='ez-toc-list ez-toc-list-level-1 ' ><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-1" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%A9_What_%E2%80%9Ctraining_on_open_source_code%E2%80%9D_means_in_legal_terms" >ğŸ§© What â€œtraining on open source codeâ€ means in legal terms</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-2" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%E2%9A%96%EF%B8%8F_Big-picture_what_the_law_actually_says_so_far" >âš–ï¸ Big-picture: what the law actually says so far</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-3" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%8F%B7%EF%B8%8F_What_the_major_license_families_actually_require" >ğŸ·ï¸ What the major license families actually require</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-4" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%94%8D_Quick_comparison_of_license_families" >ğŸ” Quick comparison of license families</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-5" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%AA_Are_models_trained_on_GPL_code_automatically_GPL" >ğŸ§ª Are models trained on GPL code automatically GPL?</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-6" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%92%A5_Case_study_GitHub_Copilot_and_open-source_code" >ğŸ’¥ Case study: GitHub Copilot and open-source code</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-7" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%93%8A_Risk_map_training_vs_outputs_vs_products" >ğŸ“Š Risk map: training vs outputs vs products</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-8" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%BE_What_MIT_GPL_Apache_%E2%80%9Cactually_say%E2%80%9D_for_AI_builders" >ğŸ§¾ What MIT, GPL, Apache â€œactually sayâ€ for AI builders</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-9" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%E2%9C%85_MIT_BSD_permissive_but_not_%E2%80%9Cno_strings%E2%80%9D" >âœ… MIT / BSD: permissive, but not â€œno stringsâ€</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-10" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%B7_Apache_20_permissive_patent_layer" >ğŸ§· Apache 2.0: permissive + patent layer</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-11" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%A8_GPL_AGPL_copyleft_but_not_clearly_%E2%80%9Cmodel-infectious%E2%80%9D" >ğŸ§¨ GPL / AGPL: copyleft, but not clearly â€œmodel-infectiousâ€</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-12" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%A7%AD_Practical_guardrails_for_teams_training_on_open_source_code" >ğŸ§­ Practical guardrails for teams training on open source code</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-13" href="https://terms.law/2025/12/05/training-on-open-source-code-what-gpl-mit-and-other-licenses-actually-say-about-ai/#%F0%9F%93%8C_Takeaways" >ğŸ“Œ Takeaways</a></li></ul></nav></div>
<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%A9_What_%E2%80%9Ctraining_on_open_source_code%E2%80%9D_means_in_legal_terms"></span>ğŸ§© What â€œtraining on open source codeâ€ means in legal terms<span class="ez-toc-section-end"></span></h2>



<p>When lawyers and engineers talk past each other, itâ€™s usually because theyâ€™re pointing at different parts of the AI stack.</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>ğŸ”§ Layer</th><th>Whatâ€™s actually happening</th><th>Why lawyers care</th></tr></thead><tbody><tr><td><strong>Training data (code corpus)</strong></td><td>You copy massive amounts of source code into a dataset</td><td>Copying &amp; storage of copyrighted works; license terms on that code apply here</td></tr><tr><td><strong>Training process</strong></td><td>You run training code over that corpus to produce model weights</td><td>Uses the copied code but usually stays internal; licenses rarely regulate <em>internal</em> use</td></tr><tr><td><strong>Model (weights + architecture)</strong></td><td>A big matrix of parameters that statistically encode patterns in the code</td><td>Debate: is this a â€œderivative workâ€ or just statistics? No court has squarely said â€œa trained model is a derivative of GPL code.â€ </td></tr><tr><td><strong>Outputs (generated code)</strong></td><td>Snippets and files produced for users</td><td>If outputs substantially reproduce licensed code, downstream users may have to comply with those licenses</td></tr><tr><td><strong>Downstream product</strong></td><td>Your SaaS, IDE plugin, or closed-source app</td><td>This is where GPL/AGPL, attribution and share-alike duties may bite if outputs or integrated code are licensed</td></tr></tbody></table></figure>



<p>Three separate legal regimes are in play:</p>



<ul class="wp-block-list">
<li><strong>Copyright</strong> (is training or output an infringing â€œcopyâ€ or â€œderivative workâ€?)</li>



<li><strong>License / contract</strong> (did you agree to conditions on how you can copy/use that code, even if copyright might allow more?)</li>



<li><strong>Community definitions</strong> (OSIâ€™s Open Source AI Definition, FSFâ€™s â€œfree MLâ€ criteria) which shape expectations but donâ€™t themselves create liability. (</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%E2%9A%96%EF%B8%8F_Big-picture_what_the_law_actually_says_so_far"></span>âš–ï¸ Big-picture: what the law actually says so far<span class="ez-toc-section-end"></span></h2>



<p>A few points are reasonably clear, and a few are very much not:</p>



<ul class="wp-block-list">
<li>Courts have started to say <strong>AI training can be copyright infringement</strong> when it uses proprietary content to compete with the rightsholder (e.g. Thomson Reuters v. Ross â€“ legal research headnotes). </li>



<li>In the <strong>GitHub Copilot</strong> litigation, most claims were dismissed, but <strong>open-source license and DMCA â€œremoval of copyright management informationâ€ claims survived</strong>, meaning a U.S. court is willing to treat license-based theories around training and regurgitation seriously. </li>



<li>A detailed 2025 survey of the â€œGPL propagates to modelsâ€ theory notes: <strong>no court has yet held that a trained model itself must be GPL because it was trained on GPL code</strong>, and mainstream community actors (OSI, FSF, SFC) are cautious about pushing that theory into precedent. (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</li>



<li>The <strong>Open Source AI Definition 1.0 (OSI)</strong> requires open code, model parameters and detailed information about training data for an AI system to be called â€œopen source,â€ but it <strong>does not require releasing all training data itself</strong> â€“ focusing on transparency and reproducibility instead. (<a href="https://opensource.org/ai/open-source-ai-definition?utm_source=chatgpt.com">Open Source Initiative</a>)</li>



<li>FSF, in contrast, is working on criteria where a â€œfreeâ€ ML application would require <strong>training data and scripts themselves to be free</strong>, but thatâ€™s an ethical/definitional stance, not an interpretation that current GPL text already covers models. </li>
</ul>



<p>The net: <strong>training on open source code is not automatically illegal</strong>, but it is also not a free-for-all. Risk is concentrated around:</p>



<ul class="wp-block-list">
<li>Ignoring license conditions (attribution, notices, copyleft)</li>



<li>Shipping models that memorise and reproduce licensed code</li>



<li>Downstream users pasting those outputs into closed-source products.</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%8F%B7%EF%B8%8F_What_the_major_license_families_actually_require"></span>ğŸ·ï¸ What the major license families actually require<span class="ez-toc-section-end"></span></h2>



<p>None of the classic FOSS licenses mention â€œAIâ€ or â€œtraining.â€ They regulate <strong>copying, modifying, and distributing</strong> software and derivatives. AI training is shoehorned into those concepts.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%94%8D_Quick_comparison_of_license_families"></span>ğŸ” Quick comparison of license families<span class="ez-toc-section-end"></span></h3>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>License family</th><th>Typical obligations</th><th>Where AI training intersects</th></tr></thead><tbody><tr><td><strong>MIT / BSD (permissive)</strong></td><td>Keep copyright &amp; license notice when you redistribute code or substantial portions; otherwise broad freedom of use</td><td>Training internally on MIT/BSD code is generally within the license grant. Risk appears if your model <em>reproduces</em> recognizable chunks and users ship them without required notices. (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</td></tr><tr><td><strong>Apache 2.0 (permissive + patents)</strong></td><td>Keep license &amp; NOTICE file on distribution; grant / receive patent license; some conditions around patent suits</td><td>Similar to MIT/BSD for training; but if outputs or tools embed Apache-licensed code, you must preserve required notices. Patent grant rarely matters for pure training, more so when models or tools embody patented techniques from the original project.</td></tr><tr><td><strong>GPLv2/v3 (strong copyleft)</strong></td><td>If you distribute a program that is a derivative of GPL code or â€œcontainsâ€ it, you must license the whole work under GPL and provide source; internal use is unrestricted</td><td>Training on GPL code without distributing the training corpus is likely permitted under the license text. The open question is whether the <strong>model or its outputs</strong> are â€œderivative worksâ€ or â€œworks containing the Program.â€ No court has said â€œyesâ€ yet, and major community analyses are skeptical that models fit easily into that definition. (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</td></tr><tr><td><strong>LGPL (weak copyleft)</strong></td><td>Copyleft mainly for modifications to the library itself; dynamic linking from proprietary apps allowed; source obligations targeted at the library</td><td>Training on LGPL code is similar to GPL at the training phase but, again, itâ€™s unclear how a model could be said to â€œcontainâ€ a library in the LGPL sense. Practical risk is mostly around verbatim output of library code.</td></tr><tr><td><strong>MPL 2.0 (file-level copyleft)</strong></td><td>Only files you modify or create based on MPL-covered files must remain MPL; you may combine them with proprietary code</td><td>Training on MPL code doesnâ€™t trigger obvious MPL duties on the model. But if an AI assistant regurgitates an MPL-licensed file or substantial portion, and a developer ships it, those specific files must remain MPL-licensed and source-available.</td></tr><tr><td><strong>AGPL (network copyleft)</strong></td><td>Like GPL but extends to software offered over a network (SaaS); if users interact with the AGPL software over a network, theyâ€™re entitled to source</td><td>AGPL is most dangerous for <strong>using AGPL code directly in your service</strong>, not for training per se. That said, if a model-powered SaaS embeds AGPL snippets from outputs into server-side code, AGPLâ€™s network copyleft can be triggered.</td></tr></tbody></table></figure>



<p>A key point: <strong>most open-source licenses focus on distribution, not pure internal use.</strong> Training is mostly an internal act. The legal heat arrives when:</p>



<ul class="wp-block-list">
<li>You <em>distribute</em> the model or tools in a way that arguably makes them derivatives of licensed code, or</li>



<li>Users ship <strong>generated code</strong> that is substantially similar to licensed works without complying with those licenses. (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%AA_Are_models_trained_on_GPL_code_automatically_GPL"></span>ğŸ§ª Are models trained on GPL code automatically GPL?<span class="ez-toc-section-end"></span></h2>



<p>Short answer: <strong>today, no one can honestly say â€œyesâ€ as a matter of settled law.</strong></p>



<p>A 2025 deep dive on â€œGPL propagation to AI modelsâ€ summarizes the current state like this: (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</p>



<ul class="wp-block-list">
<li><strong>Copyright theory:</strong> Most courts and scholars that have looked at training models (e.g. in image and music cases) are hesitant to treat <strong>the model itself</strong> as a reproduction or derivative of the training works, except in extreme cases where it is engineered to spit out specific works verbatim at high frequency.</li>



<li><strong>GPL text:</strong> GPL is written around human-readable source and programs that <em>contain</em> or <em>link</em> GPL code. It doesnâ€™t clearly cover statistical parameter matrices that may only encode tiny traces of GPL code among billions of weights.</li>



<li><strong>â€œPreferred form for modificationâ€:</strong> If you insisted a model is a GPL derivative, what is the â€œsourceâ€? The weights are not human-modifiable in a meaningful sense; the training data is not the â€œsourceâ€ of the model in the GPL sense either. The license text simply wasnâ€™t drafted with models in mind.</li>



<li><strong>Community bodies:</strong>
<ul class="wp-block-list">
<li>OSIâ€™s Open Source AI Definition requires disclosing model code, parameters and detailed data information, but <strong>does not require publishing all training data</strong>, and does <em>not</em> say that GPL necessarily â€œpropagatesâ€ to models. (<a href="https://opensource.org/ai/open-source-ai-definition?utm_source=chatgpt.com">Open Source Initiative</a>)</li>



<li>FSF is working on a new statement for free ML applications that would require training data to be free to call an ML app â€œfree,â€ but that is a <strong>new criteria</strong>, not a reinterpretation of the current GPL. (<a href="https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications">Free Software Foundation</a>)</li>
</ul>
</li>
</ul>



<p>So at the moment:</p>



<ul class="wp-block-list">
<li><strong>Risk of â€œyour model is now GPLâ€ is real in advocacy, theoretical in doctrine, and untested in court.</strong></li>



<li>What <em>is</em> very real is the risk that <strong>outputs containing GPL code</strong> pull downstream users into GPL obligations on their own software.</li>
</ul>



<p>From a practical risk perspective, many serious AI teams treat GPL/AGPL-licensed code in training data as <strong>high-friction</strong> and either:</p>



<ul class="wp-block-list">
<li>Exclude it outright from training corpora, or</li>



<li>Keep it in separate, trackable buckets, or</li>



<li>Accept it only for models theyâ€™re comfortable releasing under strong copyleftâ€“style terms. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%92%A5_Case_study_GitHub_Copilot_and_open-source_code"></span>ğŸ’¥ Case study: GitHub Copilot and open-source code<span class="ez-toc-section-end"></span></h2>



<p>The Copilot class action is the main testbed for these issues. Developers sued Microsoft, GitHub and OpenAI, alleging that: (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</p>



<ul class="wp-block-list">
<li>Copilot was trained on massive amounts of GitHub code licensed under MIT, GPL, Apache and others.</li>



<li>The system sometimes emits code that is nearly identical to open-source repositories, but <strong>without attribution or license notices</strong>.</li>



<li>Training and output therefore violate license terms requiring attribution, copyright notices, and (for copyleft licenses) share-alike obligations.</li>



<li>Copilot at times strips or omits copyright management information (e.g. headers with author names), which plaintiffs argue violates the DMCAâ€™s Â§1202 prohibitions.</li>
</ul>



<p>The federal court in California:</p>



<ul class="wp-block-list">
<li><strong>Dismissed many broad and speculative claims</strong>, especially those not tied to specific works.</li>



<li>But <strong>allowed two key claims to proceed</strong>: open-source license breach and DMCA Â§1202 â€œremoval of copyright management information.â€ (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</li>
</ul>



<p>That tells us:</p>



<ul class="wp-block-list">
<li>Courts are <strong>prepared to treat open-source licenses as enforceable contracts</strong> in the AI training context.</li>



<li>The biggest exposure, for now, lies not in abstract â€œtraining is infringementâ€ theories, but in <strong>concrete regurgitation</strong> of licensed code <strong>without complying with license conditions</strong>.</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%93%8A_Risk_map_training_vs_outputs_vs_products"></span>ğŸ“Š Risk map: training vs outputs vs products<span class="ez-toc-section-end"></span></h2>



<p>Hereâ€™s a simplified risk matrix for training on open-source code:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Scenario</th><th>Example</th><th>Relative legal risk (today)</th><th>Why</th></tr></thead><tbody><tr><td><strong>Internal training on largely permissive code (MIT/BSD/Apache), no external model distribution</strong></td><td>Firm trains an internal coding assistant on curated GitHub repos and uses it only inside the org</td><td><strong>Low â†’ Moderate</strong></td><td>Licenses broadly allow use and modification; no distribution of code or model. Risk increases if outputs are copied verbatim into shipped products without attribution. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</td></tr><tr><td><strong>Training a public model on mixed code including GPL/AGPL, with no control on memorisation</strong></td><td>Start-up releases weights of a model trained on â€œall of GitHubâ€</td><td><strong>Moderate â†’ High (license &amp; PR)</strong></td><td>No case has forced a model to go GPL, but plaintiffs can plausibly allege license breach and DMCA issues if model produces identifiable GPL snippets. Community backlash is almost guaranteed. (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</td></tr><tr><td><strong>AI coding assistant used to generate snippets inserted into closed-source products</strong></td><td>Dev pastes a 30-line function suggested by a Copilot-like tool into proprietary app</td><td><strong>Moderate â†’ High (downstream)</strong></td><td>If that snippet is protectable expression copied from GPL/MIT/Apache code, the <strong>developer</strong> may have to comply with that license (GPL share-alike, MIT/Apache attribution, etc.). This is independent of whether training was lawful. (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</td></tr><tr><td><strong>Model tuned on proprietary code that competes with rightsholderâ€™s product</strong></td><td>Training a legal-research AI on Westlaw headnotes or similar</td><td><strong>High (copyright)</strong></td><td>Thomson Reuters v. Ross suggests courts are willing to find AI training outright infringing where the AI product serves the same market and leans on proprietary content. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</td></tr><tr><td><strong>Open-source AI model released under a clear OSS license with curated, documented training data</strong></td><td>Model, code and training data info released under consistent OSI-approved licenses</td><td><strong>Lower but not zero</strong></td><td>Aligns best with OSIâ€™s Open Source AI Definition. Remaining risk is mainly around inclusion of third-party code whose licenses were misapplied or misunderstood. (<a href="https://opensource.org/ai/open-source-ai-definition?utm_source=chatgpt.com">Open Source Initiative</a>)</td></tr></tbody></table></figure>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%BE_What_MIT_GPL_Apache_%E2%80%9Cactually_say%E2%80%9D_for_AI_builders"></span>ğŸ§¾ What MIT, GPL, Apache â€œactually sayâ€ for AI builders<span class="ez-toc-section-end"></span></h2>



<p>Putting it concretely for the three licenses most people worry about:</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="%E2%9C%85_MIT_BSD_permissive_but_not_%E2%80%9Cno_strings%E2%80%9D"></span>âœ… MIT / BSD: permissive, but not â€œno stringsâ€<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>They <strong>grant very broad rights to use, copy, modify, and merge the code for any purpose</strong>, including commercial.</li>



<li>The main condition is that if you <strong>redistribute the code or substantial portions</strong>, you must include the copyright notice and license text. (<a href="https://nordialaw.com/insights-open-source-piracy-through-ai/">Nordia Law</a>)</li>



<li>Training internally on MIT/BSD code is squarely inside those grants, and thereâ€™s no textual ban on machine learning.</li>
</ul>



<p>Where problems arise:</p>



<ul class="wp-block-list">
<li>If your model <strong>memorises and outputs an MIT-licensed file or recognisable chunk</strong>, and someone ships it in a product <strong>without</strong> notices, <em>that</em> redistribution is non-compliant â€” even though training itself might be OK.</li>



<li>Enterprises are therefore building <strong>license-aware filters and attribution systems</strong> so they can show provenance for code suggestions where possible. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%B7_Apache_20_permissive_patent_layer"></span>ğŸ§· Apache 2.0: permissive + patent layer<span class="ez-toc-section-end"></span></h3>



<ul class="wp-block-list">
<li>Similar to MIT in allowing broad use, but adds:
<ul class="wp-block-list">
<li>A <strong>patent license/grant</strong>, and</li>



<li>Conditions about preserving a NOTICE file and certain attributions on redistribution. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</li>
</ul>
</li>



<li>For training, the big legal question is less about patents and more about <strong>not losing attribution and notices</strong> when code is regurgitated as suggestions.</li>
</ul>



<p>In practice:</p>



<ul class="wp-block-list">
<li>Training on Apache 2.0 code is generally seen as acceptable within the license grant, especially for internal models.</li>



<li>If your assistant suggests an Apache-licensed function and a dev ships it, you may need mechanisms to:
<ul class="wp-block-list">
<li>Detect that it came from Apache-licensed code, and</li>



<li>Help the dev preserve NOTICE and license text where appropriate.</li>
</ul>
</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%A8_GPL_AGPL_copyleft_but_not_clearly_%E2%80%9Cmodel-infectious%E2%80%9D"></span>ğŸ§¨ GPL / AGPL: copyleft, but not clearly â€œmodel-infectiousâ€<span class="ez-toc-section-end"></span></h3>



<p>What the text clearly does:</p>



<ul class="wp-block-list">
<li>Gives you permission to copy, modify and run GPL code internally, for any purpose.</li>



<li>Says that if you <strong>distribute a program that is a derivative work of GPL code or that â€œcontainsâ€ it</strong>, you must license the whole work under GPL and provide source.</li>



<li>AGPL extends this to <strong>software offered over a network</strong>, not just distributed binaries. (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</li>
</ul>



<p>What is <em>not</em> clear:</p>



<ul class="wp-block-list">
<li>Whether a trained model â€œcontainsâ€ the GPL program in the textual sense, or is a derivative work.</li>



<li>Whether distributing model weights counts as distributing a derivative work of the training code.</li>



<li>What the â€œpreferred form for modificationâ€ is for a model (weights? training data? training code?). (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</li>
</ul>



<p>Community and scholarship right now largely agree on two operational points:</p>



<ol class="wp-block-list">
<li><strong>Claiming â€œthis model is GPL because it saw GPL codeâ€ is, at best, a long shot</strong> and, at worst, counter-productive to the open-source ecosystem. (<a href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/">Open Source Guy</a>)</li>



<li><strong>Using AI tools to copy GPL snippets into closed products is a very real compliance risk</strong>, even if no one ever proves license propagation to the model itself.</li>
</ol>



<p>For cautious teams, that usually translates to either:</p>



<ul class="wp-block-list">
<li>Avoid GPL/AGPL code in training entirely; or</li>



<li>Restrict it to clearly marked projects where the resulting model and tools will be released under fully open terms compatible with copyleft. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%AD_Practical_guardrails_for_teams_training_on_open_source_code"></span>ğŸ§­ Practical guardrails for teams training on open source code<span class="ez-toc-section-end"></span></h2>



<p>Instead of abstract â€œdonâ€™t do thatâ€ rules, hereâ€™s a more operational, table-style playbook:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Situation</th><th>Sensible guardrail</th></tr></thead><tbody><tr><td>Building a <strong>general-purpose coding assistant</strong></td><td>Prefer permissive-only corpora (MIT/BSD/Apache). If GPL/AGPL must be included, track it as a separate tag and implement filters to avoid regurgitation, especially of full files or distinctive functions. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</td></tr><tr><td>Letting devs <strong>paste suggestions directly into products</strong></td><td>Add IDE warnings when suggestions match known repos or when similarity crosses a threshold; encourage devs to treat AI suggestions like StackOverflow code: check license before shipping.</td></tr><tr><td>Releasing <strong>models or copilot products publicly</strong></td><td>Maintain a training data inventory that at least distinguishes permissive, copyleft, proprietary, and â€œunknownâ€ sources. Avoid marketing your model as â€œfully open sourceâ€ unless it fits OSIâ€™s Open Source AI Definition (code + weights + data information under OSI-approved licenses). (<a href="https://opensource.org/ai/open-source-ai-definition?utm_source=chatgpt.com">Open Source Initiative</a>)</td></tr><tr><td>Running on <strong>customer codebases</strong></td><td>Treat customer code as high-sensitivity, contract-governed data. Segment models trained on customer repos from those trained on internet-scale OSS, and be explicit in contracts about training rights vs. inference-only use.</td></tr><tr><td>Using <strong>open-weight models</strong> that were themselves trained on unknown or mixed code</td><td>Read the model license; many â€œopenâ€ models are actually â€œopen-weightâ€ with non-commercial or usage restrictions. Donâ€™t assume theyâ€™re safe to embed in commercial dev tools just because the weights are downloadable. (<a href="https://www.hunton.com/insights/publications/part-1-open-source-ai-models-how-open-are-they-really?utm_source=chatgpt.com">Hunton Andrews Kurth</a>)</td></tr></tbody></table></figure>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%93%8C_Takeaways"></span>ğŸ“Œ Takeaways<span class="ez-toc-section-end"></span></h2>



<ul class="wp-block-list">
<li><strong>No major FOSS license currently speaks the language of â€œAI training,â€</strong> so weâ€™re mapping 1990s text onto 2025 technology.</li>



<li>For <strong>MIT / BSD / Apache</strong>, the main legal tension is between:
<ul class="wp-block-list">
<li>Broad permission to use and modify code (including for training), and</li>



<li>Attribution / notice duties when code (or recognisable chunks of it) are redistributed via model outputs.</li>
</ul>
</li>



<li>For <strong>GPL / AGPL / MPL</strong>, the realistic risk today is less â€œyour model is now GPLâ€ and more:
<ul class="wp-block-list">
<li><strong>Outputs carrying copyleft code into closed products</strong>, and</li>



<li>The possibility that future courts or regulators push toward some form of license propagation in extreme memorisation scenarios.</li>
</ul>
</li>



<li>Courts are moving from â€œabstract fair use argumentsâ€ to <strong>granular, fact-intensive analyses</strong> of how models were trained and what they output â€“ making documentation, provenance tracking, and output filtering central risk controls. (<a href="https://astraea.law/insights/ai-training-data-copyright">Astraea Counsel</a>)</li>
</ul>



<p>From an AI builderâ€™s perspective, the safest posture right now is:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><strong>Treat open-source code as licensed, not â€œfree fuelâ€; design your training and tooling so you could explain, under oath, which licenses you relied on, how you complied with them, and how you prevent your model from becoming a code-copying machine.</strong></p>
</blockquote>
</div>
    </article>
  </main>

  <footer><p>Â© 2025 Terms.Law. All rights reserved.</p></footer>
</body>
</html>