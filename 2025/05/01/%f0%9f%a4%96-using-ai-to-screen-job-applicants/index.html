<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-901N2Y3CDZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-901N2Y3CDZ');
    </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ğŸ¤– Using AI To Screen Job Applicants | Terms.Law</title>
  <meta name="description" content="The article discusses the challenges and legal implications of using AI in hiring processes. It emphasizes that despite promises of objectivity and efficiency, ">
  <link rel="canonical" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/shared/styles.css">
</head>
<body>
  <div id="site-header"></div>
  <script src="/shared/header-loader.js"></script>

  <main>
    <article>
      <h1>ğŸ¤– Using AI To Screen Job Applicants</h1>
      <div class="meta">Published: May 1, 2025 â€¢ AI, Contractors &amp; Employees</div>
      <div class="content">
<p><strong>Bias, explainability and what HR canâ€™t outsource to a model</strong></p>



<p>AI in hiring sounds irresistible: less time screening rÃ©sumÃ©s, more â€œobjectiveâ€ rankings, better candidates at scale.</p>



<p>But when a model quietly decides who gets an interview and who never hears back, youâ€™ve moved your legal risk right into the algorithm.</p>



<p>Regulators have already started treating AI screening as just another hiring practice, not a magic exemption:</p>



<ul class="wp-block-list">
<li>The EEOCâ€™s first AI-discrimination settlement involved <strong>hiring software that auto-rejected women 55+ and men 60+</strong> for tutoring roles. (<a href="https://www.eeoc.gov/newsroom/itutorgroup-pay-365000-settle-eeoc-discriminatory-hiring-suit?utm_source=chatgpt.com">EEOC</a>)</li>



<li>New York Cityâ€™s <strong>Local Law 144</strong> requires <strong>bias audits and candidate notices</strong> for many automated employment decision tools. (<a href="https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page?utm_source=chatgpt.com">New York City Government</a>)</li>



<li>Illinois regulates <strong>AI video interview tools</strong> and has passed broader AI-in-employment amendments to its Human Rights Act, effective 2026. (<a href="https://www.ilga.gov/Legislation/publicacts/view/101-0260?utm_source=chatgpt.com">Illinois General Assembly</a>)</li>



<li>In the EU, AI used for <strong>recruitment and employment</strong> is treated as a <em>high-risk</em> category under the AI Act, with strict transparency and oversight requirements. (<a href="https://artificialintelligenceact.eu/annex/3/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>
</ul>



<p>This piece is about where the real line is:</p>



<ul class="wp-block-list">
<li>What modern AI hiring tools actually do</li>



<li>How bias sneaks in, even when you ban â€œprotected-class fieldsâ€</li>



<li>Why explainability matters legally and practically</li>



<li>What HR teams still <em>must</em> own, no matter how â€œsmartâ€ the software claims to be</li>
</ul>



<p>No numbered headings so your WordPress TOC can do its thing.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div id="ez-toc-container" class="ez-toc-v2_0_79_2 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction">
<div class="ez-toc-title-container">
<p class="ez-toc-title" style="cursor:inherit">Contents</p>
<span class="ez-toc-title-toggle"><a href="#" class="ez-toc-pull-right ez-toc-btn ez-toc-btn-xs ez-toc-btn-default ez-toc-toggle" aria-label="Toggle Table of Content"><span class="ez-toc-js-icon-con"><span class=""><span class="eztoc-hide" style="display:none;">Toggle</span><span class="ez-toc-icon-toggle-span"><svg style="fill: #999;color:#999" xmlns="http://www.w3.org/2000/svg" class="list-377408" width="20px" height="20px" viewBox="0 0 24 24" fill="none"><path d="M6 6H4v2h2V6zm14 0H8v2h12V6zM4 11h2v2H4v-2zm16 0H8v2h12v-2zM4 16h2v2H4v-2zm16 0H8v2h12v-2z" fill="currentColor"></path></svg><svg style="fill: #999;color:#999" class="arrow-unsorted-368013" xmlns="http://www.w3.org/2000/svg" width="10px" height="10px" viewBox="0 0 24 24" version="1.2" baseProfile="tiny"><path d="M18.2 9.3l-6.2-6.3-6.2 6.3c-.2.2-.3.4-.3.7s.1.5.3.7c.2.2.4.3.7.3h11c.3 0 .5-.1.7-.3.2-.2.3-.5.3-.7s-.1-.5-.3-.7zM5.8 14.7l6.2 6.3 6.2-6.3c.2-.2.3-.5.3-.7s-.1-.5-.3-.7c-.2-.2-.4-.3-.7-.3h-11c-.3 0-.5.1-.7.3-.2.2-.3.5-.3.7s.1.5.3.7z"/></svg></span></span></span></a></span></div>
<nav><ul class='ez-toc-list ez-toc-list-level-1 ' ><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-1" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%A9_What_AI_Screening_Tools_Actually_Look_Like" >ğŸ§© What AI Screening Tools Actually Look Like</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-2" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%E2%9A%96%EF%B8%8F_The_Legal_Lens_Same_Old_Discrimination_New_Delivery_Mechanism" >âš–ï¸ The Legal Lens: Same Old Discrimination, New Delivery Mechanism</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-3" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Core_anti-discrimination_rules_still_drive_the_analysis" >Core anti-discrimination rules still drive the analysis</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-4" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#AI-specific_and_local_rules_are_layering_on" >AI-specific and local rules are layering on</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-5" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%8E%AF_Where_Bias_Creeps_In_Even_When_You_Remove_%E2%80%9CProtected_Fields%E2%80%9D" >ğŸ¯ Where Bias Creeps In (Even When You Remove â€œProtected Fieldsâ€)</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-6" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Typical_bias_channels_in_AI_hiring" >Typical bias channels in AI hiring</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-7" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%A0_Explainability_Why_%E2%80%9CThe_Model_Said_So%E2%80%9D_Isnt_Good_Enough" >ğŸ§  Explainability: Why â€œThe Model Said Soâ€ Isnâ€™t Good Enough</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-8" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#You_still_need_a_story_you_can_tell_out_loud" >You still need a story you can tell out loud</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-9" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Regulatory_and_litigation_angles" >Regulatory and litigation angles</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-10" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%8D%E2%80%8D%E2%99%80%EF%B8%8F_What_HR_Cannot_Outsource_To_A_Model" >ğŸ§â€â™€ï¸ What HR Cannot Outsource To A Model</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-11" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#1_Deciding_what_%E2%80%9Cqualified%E2%80%9D_means" >1. Deciding what â€œqualifiedâ€ means</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-12" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#2_The_duty_to_provide_reasonable_accommodations" >2. The duty to provide reasonable accommodations</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-13" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#3_Evaluating_disparate_impact_and_fixing_it" >3. Evaluating disparate impact and fixing it</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-14" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#4_Dealing_with_close_cases_exceptions_and_context" >4. Dealing with close cases, exceptions and context</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-15" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%BE_What_HR_Should_Demand_From_AI_Vendors" >ğŸ§¾ What HR Should Demand From AI Vendors</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-16" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%B1_Designing_A_Legally_Defensible_AI_Screening_Program" >ğŸ§± Designing A Legally Defensible AI Screening Program</a><ul class='ez-toc-list-level-3' ><li class='ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-17" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Start_with_a_non-AI_baseline" >Start with a non-AI baseline</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-18" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Use_AI_as_decision_support_not_decision_replacement" >Use AI as decision support, not decision replacement</a></li><li class='ez-toc-page-1 ez-toc-heading-level-3'><a class="ez-toc-link ez-toc-heading-19" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#Implement_ongoing_not_one-time_bias_monitoring" >Implement ongoing, not one-time, bias monitoring</a></li></ul></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-20" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%F0%9F%A7%91%E2%80%8D%F0%9F%92%BC_Candidate_Perspective_What_You_Can_And_Cant_Do_About_AI_Screening" >ğŸ§‘â€ğŸ’¼ Candidate Perspective: What You Can And Canâ€™t Do About AI Screening</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-21" href="https://terms.law/2025/05/01/%f0%9f%a4%96-using-ai-to-screen-job-applicants/#%E2%9C%85_Quick_Checklist_What_HR_Cant_Outsource_To_A_Model" >âœ… Quick Checklist: What HR Canâ€™t Outsource To A Model</a></li></ul></nav></div>
<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%A9_What_AI_Screening_Tools_Actually_Look_Like"></span>ğŸ§© What AI Screening Tools Actually Look Like<span class="ez-toc-section-end"></span></h2>



<p>Most tools marketed as â€œAI hiringâ€ are variations on familiar themes:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Tool type</th><th>What it does</th><th>AIâ€™s role</th><th>Main legal risk</th></tr></thead><tbody><tr><td><strong>RÃ©sumÃ© parsers &amp; ranking systems</strong></td><td>Parse CVs, assign scores, auto-rank or auto-reject candidates</td><td>NLP models extract entities, predict â€œfitâ€ from prior hiring data</td><td>Disparate impact; opaque criteria eliminate protected groups in bulk</td></tr><tr><td><strong>Video interview analyzers</strong></td><td>Score recorded or live interviews</td><td>Models analyze speech, word choice, sometimes facial expressions</td><td>Bias against accents, disabilities; emotion/face analysis risk; notice/consent rules (e.g. Illinois AIVIA)</td></tr><tr><td><strong>Chatbot pre-screeners</strong></td><td>Conduct initial Q&amp;A, knock out candidates below a threshold</td><td>Models interpret answers, enforce cut-offs on skills, gaps, salary</td><td>Poorly chosen filters as proxies for age, disability or pregnancy</td></tr><tr><td><strong>Gamified / psychometric tests</strong></td><td>Online games or assessments; produce a â€œfit scoreâ€</td><td>Models map behavior to success based on historic employees</td><td>Encodes past bias; hard to explain; FCRA and disability issues</td></tr><tr><td><strong>End-to-end ATS â€œAI layersâ€</strong></td><td>Score, route and prioritize candidates through pipeline</td><td>Combine multiple signals into a single â€œhireabilityâ€ score</td><td>Black-box decisions; vendor/ employer blame game when bias surfaces</td></tr></tbody></table></figure>



<p>Legally, these tools are not special. Theyâ€™re just <strong>screening criteria</strong> under existing anti-discrimination law. If a human couldnâ€™t lawfully apply the rule, they canâ€™t launder it through a model.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%E2%9A%96%EF%B8%8F_The_Legal_Lens_Same_Old_Discrimination_New_Delivery_Mechanism"></span>âš–ï¸ The Legal Lens: Same Old Discrimination, New Delivery Mechanism<span class="ez-toc-section-end"></span></h2>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Core_anti-discrimination_rules_still_drive_the_analysis"></span>Core anti-discrimination rules still drive the analysis<span class="ez-toc-section-end"></span></h3>



<p>In the U.S., the big statutes still frame the issue:</p>



<ul class="wp-block-list">
<li><strong>Title VII</strong> â€“ race, color, religion, sex, national origin</li>



<li><strong>ADA</strong> â€“ disability and reasonable accommodations</li>



<li><strong>ADEA</strong> â€“ age 40+</li>



<li>Plus state/local protections (sexual orientation, gender identity, marital status, etc.)</li>
</ul>



<p>A few key points that matter for AI:</p>



<ul class="wp-block-list">
<li><strong>Neutral tools can still be illegal</strong>. Under disparate-impact doctrine, a seemingly-neutral practice that disproportionately harms a protected group â€” and canâ€™t be justified as <em>job-related and consistent with business necessity</em> â€” violates Title VII.</li>



<li><strong>Intent is not required</strong>. â€œWe just used what the vendor gave usâ€ is not a defense if the impact is discriminatory.</li>



<li><strong>Vendors donâ€™t replace employer liability</strong>. Courts and regulators increasingly treat vendors and employers as shared actors, not substitutes. (<a href="https://www.gentrylocke.com/article/game-on-eeoc-settles-first-ai-hiring-bias-lawsuit/?utm_source=chatgpt.com">Gentry Locke Attorneys</a>)</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="AI-specific_and_local_rules_are_layering_on"></span>AI-specific and local rules are layering on<span class="ez-toc-section-end"></span></h3>



<p>Regulators are starting to carve out AI-specific obligations:</p>



<ul class="wp-block-list">
<li><strong>NYC Local Law 144 (LL 144)</strong> â€“ requires covered AI hiring tools to undergo <strong>annual independent bias audits</strong>, and employers must <strong>post audit results</strong> and <strong>notify candidates</strong> when tools are used to evaluate them. (<a href="https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page?utm_source=chatgpt.com">New York City Government</a>)</li>



<li><strong>Illinois AI Video Interview Act (AIVIA)</strong> â€“ requires <strong>notice, explanation and consent</strong> before using AI to analyze video interviews, along with restrictions on sharing and deletion. (<a href="https://www.ilga.gov/Legislation/publicacts/view/101-0260?utm_source=chatgpt.com">Illinois General Assembly</a>)</li>



<li><strong>Illinois HB 3773 / IHRA amendments</strong> â€“ from 2026, explicitly restrict AI that causes discriminatory effects in employment decisions. (<a href="https://www.duanemorris.com/alerts/illinois_enacts_artificial_intelligence_law_focused_employment_practices_0824.html?utm_source=chatgpt.com">Duane Morris</a>)</li>



<li><strong>EU AI Act</strong> â€“ classifies AI used in employment (including recruitment) as <strong>high-risk</strong>, triggering obligations for risk management, data governance, human oversight and transparency, with staged enforcement between 2025 and 2027. (<a href="https://artificialintelligenceact.eu/annex/3/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>
</ul>



<p>The underlying theme: AI is being treated as <strong>amplified hiring</strong>, not an exotic new category.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%8E%AF_Where_Bias_Creeps_In_Even_When_You_Remove_%E2%80%9CProtected_Fields%E2%80%9D"></span>ğŸ¯ Where Bias Creeps In (Even When You Remove â€œProtected Fieldsâ€)<span class="ez-toc-section-end"></span></h2>



<p>You can strip out race, gender and age fields and <em>still</em> have biased models. The patterns creep back through proxies.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Typical_bias_channels_in_AI_hiring"></span>Typical bias channels in AI hiring<span class="ez-toc-section-end"></span></h3>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>Source of bias</th><th>What it looks like</th><th>Why itâ€™s dangerous</th></tr></thead><tbody><tr><td><strong>Biased training data</strong></td><td>Model is trained on â€œsuccessful past hires,â€ who skew male/white/young</td><td>Model learns â€œbe like past employees,â€ reproducing historical discrimination</td></tr><tr><td><strong>Proxy variables</strong></td><td>ZIP code, school attended, employment gaps, certain employers</td><td>Stand-ins for race, age, disability, pregnancy, caregiving duties</td></tr><tr><td><strong>Label bias</strong></td><td>â€œGood hireâ€ label based on subjective manager ratings</td><td>Encodes supervisor bias and passes it down as â€œground truthâ€</td></tr><tr><td><strong>Measurement bias</strong></td><td>Accent, speech speed, facial expression treated as performance</td><td>Penalizes disabilities, neurodivergence, cultural differences</td></tr><tr><td><strong>Data quality gaps</strong></td><td>Sparse or noisy data for small subgroups</td><td>Model underperforms for those groups â†’ more false negatives</td></tr></tbody></table></figure>



<p>The iTutorGroup case is the â€œobviousâ€ version: the software literally rejected applicants based on age cut-offs. (<a href="https://www.eeoc.gov/newsroom/itutorgroup-pay-365000-settle-eeoc-discriminatory-hiring-suit?utm_source=chatgpt.com">EEOC</a>)</p>



<p>But you can get a similar effect if your model quietly learns that:</p>



<ul class="wp-block-list">
<li>People with <strong>older graduation dates</strong></li>



<li>Or <strong>certain employment gaps</strong></li>



<li>Or <strong>specific low-income ZIP codes</strong></li>
</ul>



<p>are less likely to be hired â€” and then replicates that pattern at scale.</p>



<p>From a legal perspective, it doesnâ€™t matter whether a biased rule came from:</p>



<ul class="wp-block-list">
<li>One managerâ€™s â€œgut feeling,â€ or</li>



<li>A vendorâ€™s 60-page â€œproprietary AI fit modelâ€ report</li>
</ul>



<p>If the outcome is discriminatory and not adequately justified and validated, you have a problem.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%A0_Explainability_Why_%E2%80%9CThe_Model_Said_So%E2%80%9D_Isnt_Good_Enough"></span>ğŸ§  Explainability: Why â€œThe Model Said Soâ€ Isnâ€™t Good Enough<span class="ez-toc-section-end"></span></h2>



<p>When AI decides who gets interviewed, rejected or hired, someone will eventually ask:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>â€œWhy didnâ€™t I move forward?â€</p>
</blockquote>



<p>Thatâ€™s where explainability becomes more than a buzzword.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="You_still_need_a_story_you_can_tell_out_loud"></span>You still need a story you can tell out loud<span class="ez-toc-section-end"></span></h3>



<p>Even if the math is complex, HR needs to be able to say things like:</p>



<ul class="wp-block-list">
<li>â€œYour application did not move forward because the role required X, Y, Z, and the system weighted your experience in A and B lower.â€</li>



<li>â€œThe assessment is designed to measure [specific job-related traits], and your score fell below our cut-off in [specific area].â€</li>
</ul>



<p>You donâ€™t need to expose source code, but you <strong>do</strong> need:</p>



<ul class="wp-block-list">
<li>A high-level summary of <strong>input features</strong></li>



<li>Clarity about <strong>which features matter most</strong></li>



<li>A non-technical explanation of <strong>how a decision threshold works</strong></li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Regulatory_and_litigation_angles"></span>Regulatory and litigation angles<span class="ez-toc-section-end"></span></h3>



<p>Explainability ties into several doctrines and rules:</p>



<ul class="wp-block-list">
<li><strong>Disparate impact</strong> â€“ You must show the tool is <strong>job-related and consistent with business necessity</strong>, which is hard if you canâ€™t articulate what itâ€™s actually measuring.</li>



<li><strong>Adverse action and consumer-report laws</strong> â€“ If youâ€™re using third-party scoring that functions like a background report, you may have to provide adverse-action notices and a chance to dispute errors.</li>



<li><strong>EU / high-risk AI regimes</strong> â€“ Under the EU AI Act, high-risk AI systems in employment contexts must include documentation, transparency and <strong>human oversight</strong> so people understand and can contest decisions. (<a href="https://artificialintelligenceact.eu/annex/3/?utm_source=chatgpt.com">Artificial Intelligence Act</a>)</li>
</ul>



<p>From a litigation standpoint, â€œthe vendor says itâ€™s fairâ€ is not a complete answer. Courts and regulators will be interested in:</p>



<ul class="wp-block-list">
<li>Whether you <em>looked at</em> the audit reports</li>



<li>How you handled red flags</li>



<li>Whether you kept using the tool unchanged despite clear disparate impact</li>
</ul>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%8D%E2%80%8D%E2%99%80%EF%B8%8F_What_HR_Cannot_Outsource_To_A_Model"></span>ğŸ§â€â™€ï¸ What HR Cannot Outsource To A Model<span class="ez-toc-section-end"></span></h2>



<p>Thereâ€™s a natural temptation to think, â€œIf we buy the right tech, it will <strong>do fairness for us</strong>.â€</p>



<p>Thatâ€™s not how any of this works.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="1_Deciding_what_%E2%80%9Cqualified%E2%80%9D_means"></span>1. Deciding what â€œqualifiedâ€ means<span class="ez-toc-section-end"></span></h3>



<p><strong>Job-relatedness</strong> is not a model parameter; itâ€™s a human judgment.</p>



<p>Humans still have to:</p>



<ul class="wp-block-list">
<li>Define the <strong>core duties</strong> of the role</li>



<li>Decide which <strong>skills and traits actually correlate with success</strong></li>



<li>Reject â€œnice-to-havesâ€ that are just proxies for pedigree or status</li>
</ul>



<p>If your input is a vague label like â€œtop performer,â€ the model will faithfully reproduce all the prejudice that went into past performance ratings.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="2_The_duty_to_provide_reasonable_accommodations"></span>2. The duty to provide reasonable accommodations<span class="ez-toc-section-end"></span></h3>



<p>Under disability law, employers must:</p>



<ul class="wp-block-list">
<li>Consider <strong>reasonable accommodations</strong>, and</li>



<li>Engage in an <strong>interactive process</strong> with candidates and employees</li>
</ul>



<p>You canâ€™t outsource that to a bot that says â€œyour score is low, goodbye.â€</p>



<p>You still need humans to:</p>



<ul class="wp-block-list">
<li>Recognize when a candidate might be disadvantaged by the AI tool (e.g., speech disabilities, anxiety, neurodivergence)</li>



<li>Offer alternative formats (written answers instead of video, extended time, in-person interviews)</li>



<li>Adjust or waive AI-driven thresholds when needed</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="3_Evaluating_disparate_impact_and_fixing_it"></span>3. Evaluating disparate impact and fixing it<span class="ez-toc-section-end"></span></h3>



<p>Bias audits and impact analyses are <strong>governance</strong>, not pure math:</p>



<ul class="wp-block-list">
<li>Someone has to decide <strong>which metrics matter</strong></li>



<li>Someone has to decide whether an effect size is <strong>acceptable or not</strong></li>



<li>Someone has to prioritize <strong>remediation</strong> over convenience when issues show up</li>
</ul>



<p>Even where local law requires a third-party â€œbias auditâ€ (like NYC LL 144), the employer still owns the decision to keep, tweak or retire a tool. (<a href="https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page?utm_source=chatgpt.com">New York City Government</a>)</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="4_Dealing_with_close_cases_exceptions_and_context"></span>4. Dealing with close cases, exceptions and context<span class="ez-toc-section-end"></span></h3>



<p>AI is bad at nuance that law cares about:</p>



<ul class="wp-block-list">
<li>Whistleblowing or protected activity</li>



<li>Non-linear career paths</li>



<li>Caregiving gaps, military service, immigration hurdles</li>



<li>Cultural differences in communication style</li>
</ul>



<p>Those are precisely the areas where human review has to step in and ask, â€œIs this a legal risk, or just an unconventional candidate?â€</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%BE_What_HR_Should_Demand_From_AI_Vendors"></span>ğŸ§¾ What HR Should Demand From AI Vendors<span class="ez-toc-section-end"></span></h2>



<p>Youâ€™re not just buying software; youâ€™re buying <strong>shared liability</strong>.</p>



<p>Hereâ€™s a useful way to frame vendor questions:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>HRâ€™s goal</th><th>What to ask for</th><th>Red flag answers</th></tr></thead><tbody><tr><td>Understand what the tool actually does</td><td>Clear documentation of inputs, outputs, target roles, and limitations</td><td>â€œItâ€™s proprietary / magic / replaces interviews completelyâ€</td></tr><tr><td>Assess bias and legality</td><td>Recent bias audits, methods, and subgroup performance metrics</td><td>â€œWe donâ€™t track demographic impactâ€ or â€œour tool canâ€™t be biasedâ€</td></tr><tr><td>Preserve human control</td><td>Configurable thresholds, ability to override or bypass AI decisions</td><td>â€œYou must accept our default scoring pipelineâ€</td></tr><tr><td>Manage data responsibly</td><td>Details on data sources, retention, deletion and sharing with third parties</td><td>Vague answers on where candidate data goes or how long itâ€™s kept</td></tr><tr><td>Support candidatesâ€™ rights</td><td>Features for notices, consent, accommodations, and candidate appeals</td><td>No way to flag accommodations or manually re-review rejected candidates</td></tr></tbody></table></figure>



<p>If a vendor is allergic to transparency, assume the enforcement agencies wonâ€™t be sympathetic when something breaks.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%B1_Designing_A_Legally_Defensible_AI_Screening_Program"></span>ğŸ§± Designing A Legally Defensible AI Screening Program<span class="ez-toc-section-end"></span></h2>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Start_with_a_non-AI_baseline"></span>Start with a non-AI baseline<span class="ez-toc-section-end"></span></h3>



<p>Before you plug in anything â€œintelligentâ€:</p>



<ul class="wp-block-list">
<li>Define <strong>job descriptions</strong> and <strong>essential functions</strong> clearly.</li>



<li>Document <strong>valid selection criteria</strong> (skills, experience, assessments) and why theyâ€™re linked to performance.</li>



<li>Map your current process so you know exactly <strong>where</strong> AI will plug in and what decisions it will influence.</li>
</ul>



<p>AI layered on a messy, undocumented process just produces <strong>faster, more opaque mess</strong>.</p>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Use_AI_as_decision_support_not_decision_replacement"></span>Use AI as decision support, not decision replacement<span class="ez-toc-section-end"></span></h3>



<p>Safer patterns:</p>



<ul class="wp-block-list">
<li>Use AI to <strong>prioritize</strong> or <strong>flag</strong> candidates, not to automatically reject them.</li>



<li>Require <strong>human review</strong> of borderline cases, flagged anomalies and all rejections above certain risk thresholds.</li>



<li>Keep humans in charge of <strong>final hiring decisions</strong> and threshold settings.</li>
</ul>



<h3 class="wp-block-heading"><span class="ez-toc-section" id="Implement_ongoing_not_one-time_bias_monitoring"></span>Implement ongoing, not one-time, bias monitoring<span class="ez-toc-section-end"></span></h3>



<p>A good program looks more like continuous compliance than a one-off â€œauditâ€:</p>



<ul class="wp-block-list">
<li>Track selection and pass-through rates across <strong>protected groups</strong> (where you legally can, and often using statistical estimates).</li>



<li>Watch for <strong>sudden changes</strong> after a model update or new feature.</li>



<li>Document <strong>changes you make in response</strong> to impact findings: tweaks in thresholds, additional human review, alternate pathways for certain roles.</li>
</ul>



<p>If youâ€™re in a jurisdiction with explicit bias-audit duties (NYC, Illinois, coming state laws), this monitoring isnâ€™t optional anyway. (<a href="https://www.duanemorris.com/alerts/illinois_enacts_artificial_intelligence_law_focused_employment_practices_0824.html?utm_source=chatgpt.com">Duane Morris</a>)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%F0%9F%A7%91%E2%80%8D%F0%9F%92%BC_Candidate_Perspective_What_You_Can_And_Cant_Do_About_AI_Screening"></span>ğŸ§‘â€ğŸ’¼ Candidate Perspective: What You Can And Canâ€™t Do About AI Screening<span class="ez-toc-section-end"></span></h2>



<p>Candidates have less leverage but are not powerless.</p>



<p>Realistically possible steps:</p>



<ul class="wp-block-list">
<li><strong>Read the notices</strong> carefully. In some jurisdictions, employers must tell you when AI is used and what it does.</li>



<li>Where the law allows, <strong>ask about alternative formats or accommodations</strong> (e.g., a live interview instead of an AI-analyzed video).</li>



<li>If you suspect discrimination, <strong>keep records</strong> â€“ job posting, screening process description, communications, your own copies of submissions.</li>



<li>For regulated roles or jurisdictions, you may have specific rights to explanation, reconsideration, or access to certain reports.</li>
</ul>



<p>You probably canâ€™t â€œopt out of all AI,â€ but you can insist itâ€™s not the <em>only</em> word on your candidacy, especially where disability or other protected traits are at issue.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="%E2%9C%85_Quick_Checklist_What_HR_Cant_Outsource_To_A_Model"></span>âœ… Quick Checklist: What HR Canâ€™t Outsource To A Model<span class="ez-toc-section-end"></span></h2>



<p>If you remember nothing else, keep this mental list.</p>



<p>Even with the most sophisticated AI, HR still must:</p>



<ul class="wp-block-list">
<li>Set <strong>job-related criteria</strong> and articulate why they matter</li>



<li>Decide <strong>which data is fair game</strong> and which is off-limits</li>



<li>Provide <strong>reasonable accommodations</strong> and alternatives</li>



<li>Perform and act on <strong>bias and disparate-impact analyses</strong></li>



<li>Maintain <strong>human oversight</strong> for edge cases and critical decisions</li>



<li>Own the <strong>communication with candidates</strong>: notices, explanations, appeals</li>



<li>Keep <strong>records</strong> that show your process was thoughtful, not rubber-stamped</li>
</ul>



<p>The promise of AI screening is not â€œno more hard choices.â€ Itâ€™s <strong>faster, more consistent application of the choices you make</strong>.</p>



<p>If those choices are well-documented, compliant and carefully monitored, AI can help. If they arenâ€™t, AI will simply scale your problems â€” and put them in front of regulators, plaintiffsâ€™ lawyers and judges with detailed logs and time stamps.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p></p>
</div>
    </article>
  </main>

  <footer><p>Â© Terms.Law. All rights reserved.</p></footer>
</body>
</html>