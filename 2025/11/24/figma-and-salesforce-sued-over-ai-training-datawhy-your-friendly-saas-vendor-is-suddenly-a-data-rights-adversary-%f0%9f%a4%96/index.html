<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Figma and Salesforce Sued Over AI Training DataWhy Your â€œFriendly SaaS Vendorâ€ Is Suddenly a Data-Rights Adversary ğŸ¤– | Terms.Law</title>
  <meta name="description" content="Figma and Salesforce face lawsuits over unauthorized use of customer data for AI training. Figma is accused of using customer design files without consent, whil">
  <link rel="canonical" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/shared/styles.css">
</head>
<body>
  <div id="site-header"></div>
  <script src="/shared/header-loader.js"></script>

  <main>
    <article>
      <h1>Figma and Salesforce Sued Over AI Training DataWhy Your â€œFriendly SaaS Vendorâ€ Is Suddenly a Data-Rights Adversary ğŸ¤–</h1>
      <div class="meta">Published: November 24, 2025 â€¢ Dispute Resolution, News, Software</div>
      <div class="content">
<p>Figma and Salesforce are now both defendants in high-profile lawsuits over <strong>how they trained their AI models</strong>â€”and more importantly, <em>whose data</em> they used to do it.</p>



<ul class="wp-block-list">
<li>In Figmaâ€™s case, the allegation is that it quietly turned <strong>customer design files</strong> into AI training fuel, despite earlier assurances that it wouldnâ€™t. </li>



<li>In Salesforceâ€™s case, authors say the company used <strong>thousands of pirated books</strong> in datasets like RedPajama and The Pile to train its xGen models, while its CEO publicly criticized other companies for using â€œstolen data.â€ </li>
</ul>



<p>If you are a B2B buyer, SaaS founder, or anyone drafting DPAs and AI addenda, these cases are not just tech gossip. They are the <strong>roadmap for your next dispute</strong> if you donâ€™t lock down data rights in your contracts.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div id="ez-toc-container" class="ez-toc-v2_0_79_2 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction">
<div class="ez-toc-title-container">
<p class="ez-toc-title" style="cursor:inherit">Contents</p>
<span class="ez-toc-title-toggle"><a href="#" class="ez-toc-pull-right ez-toc-btn ez-toc-btn-xs ez-toc-btn-default ez-toc-toggle" aria-label="Toggle Table of Content"><span class="ez-toc-js-icon-con"><span class=""><span class="eztoc-hide" style="display:none;">Toggle</span><span class="ez-toc-icon-toggle-span"><svg style="fill: #999;color:#999" xmlns="http://www.w3.org/2000/svg" class="list-377408" width="20px" height="20px" viewBox="0 0 24 24" fill="none"><path d="M6 6H4v2h2V6zm14 0H8v2h12V6zM4 11h2v2H4v-2zm16 0H8v2h12v-2zM4 16h2v2H4v-2zm16 0H8v2h12v-2z" fill="currentColor"></path></svg><svg style="fill: #999;color:#999" class="arrow-unsorted-368013" xmlns="http://www.w3.org/2000/svg" width="10px" height="10px" viewBox="0 0 24 24" version="1.2" baseProfile="tiny"><path d="M18.2 9.3l-6.2-6.3-6.2 6.3c-.2.2-.3.4-.3.7s.1.5.3.7c.2.2.4.3.7.3h11c.3 0 .5-.1.7-.3.2-.2.3-.5.3-.7s-.1-.5-.3-.7zM5.8 14.7l6.2 6.3 6.2-6.3c.2-.2.3-.5.3-.7s-.1-.5-.3-.7c-.2-.2-.4-.3-.7-.3h-11c-.3 0-.5.1-.7.3-.2.2-.3.5-.3.7s.1.5.3.7z"/></svg></span></span></span></a></span></div>
<nav><ul class='ez-toc-list ez-toc-list-level-1 ' ><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-1" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#Two_Lawsuits_Two_Types_of_Data_One_Theme_%E2%80%9CYou_Used_Our_Stuff%E2%80%9D" >Two Lawsuits, Two Types of Data, One Theme: â€œYou Used Our Stuffâ€</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-2" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#Figma_When_%E2%80%9CYour_Files_Stay_Yours%E2%80%9D_Meets_AI_Training_%F0%9F%93%90%F0%9F%A4%96" >Figma: When â€œYour Files Stay Yoursâ€ Meets AI Training ğŸ“ğŸ¤–</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-3" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#Salesforce_Pirated_Books_Datasets_and_Public_Hypocrisy_%E2%98%81%EF%B8%8F%F0%9F%93%9A" >Salesforce: Pirated Books, Datasets, and Public Hypocrisy â˜ï¸ğŸ“š</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-4" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#Why_These_Cases_Should_Terrify_or_Focus_B2B_SaaS_Users_%F0%9F%A7%A9" >Why These Cases Should Terrify (or Focus) B2B SaaS Users ğŸ§©</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-5" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#The_Contract_Problem_Data_Rights_Clauses_Stuck_in_the_Pre-AI_Era_%F0%9F%93%9C%E2%9A%99%EF%B8%8F" >The Contract Problem: Data Rights Clauses Stuck in the Pre-AI Era ğŸ“œâš™ï¸</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-6" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#What_If_You_Suspect_Your_Vendor_Trained_on_Your_Data_Demand_Letters_101_%E2%9C%89%EF%B8%8F" >What If You Suspect Your Vendor Trained on Your Data? Demand Letters 101 âœ‰ï¸</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-7" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#For_Vendors_Dont_Be_Figma_or_Salesforce_by_Accident_%F0%9F%A7%B1" >For Vendors: Donâ€™t Be Figma or Salesforce by Accident ğŸ§±</a></li><li class='ez-toc-page-1 ez-toc-heading-level-2'><a class="ez-toc-link ez-toc-heading-8" href="https://terms.law/2025/11/24/figma-and-salesforce-sued-over-ai-training-datawhy-your-friendly-saas-vendor-is-suddenly-a-data-rights-adversary-%f0%9f%a4%96/#The_Bigger_Picture_Training_Data_Litigation_as_the_New_Normal_%E2%9A%96%EF%B8%8F" >The Bigger Picture: Training Data Litigation as the New Normal âš–ï¸</a></li></ul></nav></div>
<h2 class="wp-block-heading"><span class="ez-toc-section" id="Two_Lawsuits_Two_Types_of_Data_One_Theme_%E2%80%9CYou_Used_Our_Stuff%E2%80%9D"></span>Two Lawsuits, Two Types of Data, One Theme: â€œYou Used Our Stuffâ€<span class="ez-toc-section-end"></span></h2>



<p>Hereâ€™s the 10,000-foot comparison:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>ğŸ¢ Defendant</th><th>ğŸ“ Court &amp; Filing</th><th>ğŸ“š What Data Is at Issue</th><th>âš–ï¸ Core Legal Theories</th><th>ğŸ’£ Why Itâ€™s Interesting</th></tr></thead><tbody><tr><td>Figma ğŸ“</td><td>N.D. Cal., proposed class action filed Nov. 21, 2025 </td><td>Customer design files, layers, text, images built inside Figma</td><td>Misappropriation of trade secrets, unlawful access, misrepresentation, data privacy violations</td><td>Focuses on <strong>enterprise customer IP</strong>, not public web data; framed heavily as a <em>broken promise / contract</em> story</td></tr><tr><td>Salesforce â˜ï¸</td><td>N.D. Cal., class action filed Oct. 15â€“16, 2025 </td><td>Thousands of allegedly pirated books in training datasets (RedPajama, The Pile)</td><td>Copyright infringement, DMCA-type theories, unjust enrichment</td><td>Classic â€œpirated booksâ€ fact pattern; juxtaposed with CEOâ€™s public stance against â€œstolenâ€ AI data</td></tr></tbody></table></figure>



<p>Both cases sit in the shadow of the <strong>$1.5B Anthropic settlement</strong> with authors whose books were pulled from pirate sites for training data. </p>



<p>The message from plaintiffsâ€™ bar is pretty clear:<br><em>â€œIf Anthropic paid, why not you?â€</em></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="Figma_When_%E2%80%9CYour_Files_Stay_Yours%E2%80%9D_Meets_AI_Training_%F0%9F%93%90%F0%9F%A4%96"></span>Figma: When â€œYour Files Stay Yoursâ€ Meets AI Training ğŸ“ğŸ¤–<span class="ez-toc-section-end"></span></h2>



<p>The Figma case (Khan v. Figma Inc.) is notable because it is not about scraping public web content. Itâ€™s about what your <strong>paid, logged-in SaaS product</strong> does with the work you create inside it.</p>



<p>According to the complaint and coverage:</p>



<ul class="wp-block-list">
<li>Figma allegedly <strong>used customersâ€™ proprietary design filesâ€”layouts, components, text, images, layer metadataâ€”to train its generative AI tools</strong> without clear, informed consent. </li>



<li>Plaintiffs say Figma <strong>auto-opted users into AI training</strong>, despite previous statements and marketing suggesting that customer content would <em>not</em> be used that way without permission. </li>



<li>They claim this helped Figma boost its valuation around its 2025 IPOâ€”Reuters mentions a <strong>$1.2B raise</strong> and other reports peg its implied valuation much higher, with plaintiffs arguing the value of customer IP used for training could be â€œtens or hundreds of billions.â€ (<a href="https://www.reuters.com/legal/government/figma-sued-allegedly-misusing-customer-data-ai-training-2025-11-21/?utm_source=chatgpt.com">Reuters</a>)</li>
</ul>



<p>Figma publicly denies that it trains on customer content without permission and says its policies are being misunderstood. But the complaint is structured to look less like a pure privacy case and more like a mix of <strong>trade secret theft and broken commercial assurances.</strong> (<a href="https://longbridge.com/en/news/267024566?utm_source=chatgpt.com">Longbridge SG</a>)</p>



<p>The key allegation is simple and dangerous:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>You told us our designs were safe and under our control. Then you quietly turned them into training data.</p>
</blockquote>



<p>For enterprise design teams shipping confidential product plans through Figma, thatâ€™s not a theoretical issueâ€”itâ€™s a <strong>trade-secret threat</strong>.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="Salesforce_Pirated_Books_Datasets_and_Public_Hypocrisy_%E2%98%81%EF%B8%8F%F0%9F%93%9A"></span>Salesforce: Pirated Books, Datasets, and Public Hypocrisy â˜ï¸ğŸ“š<span class="ez-toc-section-end"></span></h2>



<p>The Salesforce suit is much closer to the Anthropic / OpenAI line of cases, but with its own twist.</p>



<p>Authors Molly Tanzer and Jennifer Gilmore allege that:</p>



<ul class="wp-block-list">
<li>Salesforce used <strong>thousands of pirated books</strong>, including theirs, by ingesting datasets like RedPajama and The Pile to train its xGen language models. (<a href="https://www.reuters.com/sustainability/boards-policy-regulation/salesforce-sued-by-authors-over-artificial-intelligence-software-2025-10-16/?utm_source=chatgpt.com">Reuters</a>)</li>



<li>These datasets were assembled from known pirate sources, so the company allegedly <strong>knew or should have known</strong> that they contained unlicensed works.</li>



<li>The suit emphasizes Salesforce CEO Marc Benioffâ€™s prior criticism of AI companies using â€œstolenâ€ training data and his statements that paying creators would be â€œeasy to do,â€ painting a picture of corporate hypocrisy. (<a href="https://www.businessinsurance.com/salesforce-sued-by-authors-over-artificial-intelligence-software/?utm_source=chatgpt.com">Business Insurance</a>)</li>
</ul>



<p>Legally, itâ€™s a straight copyright case with a strong narrative hook:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>ğŸ“š Element</th><th>ğŸ” Plaintiffsâ€™ Framing</th></tr></thead><tbody><tr><td>Source of works</td><td>â€œPirated booksâ€ from datasets whose origins are widely discussed in the AI world</td></tr><tr><td>Use</td><td>Downloading, storing, and using full copies to train xGen models</td></tr><tr><td>Ongoing conduct</td><td>Continued storage and processing, not just historical ingestion</td></tr><tr><td>CEO statements</td><td>Benioffâ€™s public stance becomes quasi-admissions about what <em>should</em> be done</td></tr></tbody></table></figure>



<p>The factual overlap with the Anthropic case (pirate-sourced datasets, authors seeking compensation) makes it easier for plaintiffs to say: <em>â€œCourts and companies already treat this as wrongful. We just havenâ€™t litigated it against Salesforce yet.â€</em> (<a href="https://people.com/after-their-books-were-pirated-to-train-ai-three-authors-went-to-court-and-won-exclusive-11844826?utm_source=chatgpt.com">People.com</a>)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="Why_These_Cases_Should_Terrify_or_Focus_B2B_SaaS_Users_%F0%9F%A7%A9"></span>Why These Cases Should Terrify (or Focus) B2B SaaS Users ğŸ§©<span class="ez-toc-section-end"></span></h2>



<p>From the customer side, Figma and Salesforce illustrate two different but related problems:</p>



<ul class="wp-block-list">
<li><strong>Figma-type risk</strong>: your own proprietary content inside a vendorâ€™s SaaS product is quietly treated as model fuel.</li>



<li><strong>Salesforce-type risk</strong>: your vendorâ€™s model is trained on other peopleâ€™s allegedly infringing content, and youâ€™re now re-using that model inside your workflows.</li>
</ul>



<p>For a typical enterprise buyer, the real questions are:</p>



<ul class="wp-block-list">
<li>Can my vendor <strong>train on our data</strong>?</li>



<li>If yes, <strong>for what purposes</strong> (maintenance, product improvement, general model training, resale)?</li>



<li>If their model turns out to be trained on infringing content, who carries the <strong>IP risk downstream</strong>â€”them or us?</li>
</ul>



<p>Right now, many DPAs and SOWs answer those questions with a vague â€œwe comply with all applicable lawsâ€ and a buried reference to the vendorâ€™s online privacy policy. Thatâ€™s not going to survive this litigation wave.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="The_Contract_Problem_Data_Rights_Clauses_Stuck_in_the_Pre-AI_Era_%F0%9F%93%9C%E2%9A%99%EF%B8%8F"></span>The Contract Problem: Data Rights Clauses Stuck in the Pre-AI Era ğŸ“œâš™ï¸<span class="ez-toc-section-end"></span></h2>



<p>Most legacy SaaS contracts were never written with â€œmodel trainingâ€ in mind. They distinguish between:</p>



<ul class="wp-block-list">
<li><strong>Customer Data</strong> (belongs to you, used to provide the service), and</li>



<li><strong>Service Data / Aggregated Data</strong> (usage metrics, logs, etc., used to improve the product).</li>
</ul>



<p>AI training sits awkwardly between those. Vendors increasingly treat training as â€œimprovement of the service.â€ Customers often view training on their actual content as a separate, licensable use.</p>



<p>Figma and Salesforce are the two archetypes of what happens when that gap is not negotiated clearly.</p>



<p>Hereâ€™s how a more AI-aware contract architecture looks:</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><thead><tr><th>ğŸ” Clause Type</th><th>ğŸ§  What It Should Address</th><th>ğŸ§· Why It Matters in Light of Figma / Salesforce</th></tr></thead><tbody><tr><td>Data-Use Grant</td><td>Spell out whether the vendor may use <em>Customer Content</em> (not just logs) for (a) providing the service, (b) improving it, (c) training generalized models.</td><td>Makes it much harder for a vendor to argue â€œimprovementâ€ includes training on your raw creative files or full text.</td></tr><tr><td>Training Opt-In / Opt-Out</td><td>Separate, express consent for model training, ideally with project-level or tenant-level controls.</td><td>Prevents auto-opt-in situations like those alleged in Figma, and gives you a paper trail of choices. (<a href="https://www.reuters.com/legal/government/figma-sued-allegedly-misusing-customer-data-ai-training-2025-11-21/?utm_source=chatgpt.com">Reuters</a>)</td></tr><tr><td>Confidential / Trade Secret Protection</td><td>Treat design files, source code, unpublished product plans, etc., as confidential/trade secrets with narrow exceptions.</td><td>Supports misappropriation claims if the vendor re-uses that content in ways never negotiated. (<a href="https://www.prismedia.ai/news/suit-alleges-figma-trained-ai-on-customers-design-files?utm_source=chatgpt.com">Prism Media</a>)</td></tr><tr><td>Third-Party Content Warranties &amp; Indemnity</td><td>Vendor warrants it has rights to training data; indemnifies you against IP claims tied to its models.</td><td>Directly targets Salesforce-type risk: if their model is built on allegedly pirated books, you have a contractual backstop. (<a href="https://www.saverilawfirm.com/our-cases/salesforce-large-language-model-litigation?utm_source=chatgpt.com">Saveri Law Firm</a>)</td></tr><tr><td>Audit / Transparency</td><td>Right to high-level disclosure of training sources (categories, not every file) and to specific info if a claim is asserted.</td><td>Makes it harder for vendors to hide behind â€œproprietaryâ€ training pipelines when youâ€™re on the hook in a third-party suit.</td></tr><tr><td>Sunset / Deletion of Training Data</td><td>Mechanism for demanding deletion or exclusion of your content from future model versions when the contract ends or upon breach.</td><td>Lines up with remedies seen in Anthropic settlement (destroying copies / excluding works from future use). (<a href="https://people.com/after-their-books-were-pirated-to-train-ai-three-authors-went-to-court-and-won-exclusive-11844826?utm_source=chatgpt.com">People.com</a>)</td></tr></tbody></table></figure>



<p>Most customers donâ€™t negotiate all of this. But after Figma and Salesforce, <em>not</em> negotiating it has a clear cost.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="What_If_You_Suspect_Your_Vendor_Trained_on_Your_Data_Demand_Letters_101_%E2%9C%89%EF%B8%8F"></span>What If You Suspect Your Vendor Trained on Your Data? Demand Letters 101 âœ‰ï¸<span class="ez-toc-section-end"></span></h2>



<p>There are two common fact patterns where your next move is a demand letter rather than quiet acceptance:</p>



<ol class="wp-block-list">
<li>You discover, or strongly suspect, that a SaaS vendor used your <strong>proprietary content</strong> (designs, code snippets, documents) to train its model without an explicit grant.</li>



<li>You learn that the vendorâ€™s model itself is under fire (Salesforce-style), and you worry about <strong>downstream liability</strong> for using it in your product or workflow.</li>
</ol>



<p>A well-structured demand letter in this context usually has three jobs:</p>



<ul class="wp-block-list">
<li><strong>Information</strong> â€“ pin the vendor down on what they did and under what theory.</li>



<li><strong>Preservation</strong> â€“ demand preservation of logs, training data, and contractual history.</li>



<li><strong>Positioning</strong> â€“ reserve your rights and frame this as a breach of contract / misrepresentation / confidentiality issue, not just â€œhurt feelings.â€</li>
</ul>



<p>In a Figma-style scenario, youâ€™re typically focusing on:</p>



<ul class="wp-block-list">
<li>what exactly the contract, ToS, and DPA said about data use;</li>



<li>any <strong>marketing or sales assurances</strong> (â€œyour designs are safe,â€ â€œwe never train on your files without consentâ€); (<a href="https://www.reuters.com/legal/government/figma-sued-allegedly-misusing-customer-data-ai-training-2025-11-21/?utm_source=chatgpt.com">Reuters</a>)</li>



<li>what you want fixed: opt-out of training, separation of your tenant from shared models, deletion of existing training copies where feasible, and potentially monetary compensation if trade secrets were exposed.</li>
</ul>



<p>In a Salesforce-style scenario, the demand may be more defensive:</p>



<ul class="wp-block-list">
<li>do you have <strong>AI IP indemnity</strong> from the vendor;</li>



<li>what representations they made about training sources;</li>



<li>whether they will defend/indemnify you in the event of third-party claims.</li>
</ul>



<p>Either way, these are not â€œsupport tickets.â€ Theyâ€™re <strong>pre-litigation documents</strong> that will be read later by a judge if things go sideways.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="For_Vendors_Dont_Be_Figma_or_Salesforce_by_Accident_%F0%9F%A7%B1"></span>For Vendors: Donâ€™t Be Figma or Salesforce by Accident ğŸ§±<span class="ez-toc-section-end"></span></h2>



<p>From the vendor side, the instinct is often to keep policies as broad as possible: â€œwe can use your content to improve the service.â€ Thatâ€™s understandable. But after these cases, the â€œdonâ€™t ask, donâ€™t tellâ€ approach to training data is starting to look like malpractice.</p>



<p>A more sustainable posture:</p>



<ul class="wp-block-list">
<li><strong>Segment training rights.</strong> Treat bug-fixing and maintaining the service differently from training generalized models. Get separate consent.</li>



<li><strong>Align marketing with contracts.</strong> Donâ€™t promise â€œwe never train on your contentâ€ if your DPA says you can. Thatâ€™s essentially the Figma theory in one sentence. (<a href="https://www.reuters.com/legal/government/figma-sued-allegedly-misusing-customer-data-ai-training-2025-11-21/?utm_source=chatgpt.com">Reuters</a>)</li>



<li><strong>Clean your upstream datasets.</strong> If your model relies on datasets like RedPajama or The Pile, you need a real theory of rights, not wishful thinking. Salesforce is being sued precisely because plaintiffs say those datasets were sourced from pirated material. (<a href="https://www.salesforceben.com/salesforce-faces-lawsuit-from-authors-over-ai-training-data/?utm_source=chatgpt.com">Salesforce Ben</a>)</li>



<li><strong>Offer real opt-outs for enterprises.</strong> Many large customers will live with some training use if they can meaningfully opt out where it matters (sensitive projects, regulated data).</li>
</ul>



<p>The alternative is to let plaintiffsâ€™ lawyers, not your product team, decide how your AI stack evolves.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading"><span class="ez-toc-section" id="The_Bigger_Picture_Training_Data_Litigation_as_the_New_Normal_%E2%9A%96%EF%B8%8F"></span>The Bigger Picture: Training Data Litigation as the New Normal âš–ï¸<span class="ez-toc-section-end"></span></h2>



<p>Taken together with Anthropicâ€™s settlement and ongoing suits against Cohere, OpenAI, and others, the Figma and Salesforce cases mark a shift:</p>



<ul class="wp-block-list">
<li>Public web scraping is no longer the only flashpoint; <strong>inside-the-app data use</strong> is now front and center. (<a href="https://www.prismedia.ai/news/lawsuits-over-ai-training-data-mount-against-major-tech-platforms?utm_source=chatgpt.com">Prism Media</a>)</li>



<li>The plaintiffsâ€™ bar has a growing <strong>playbook</strong>â€”pirated datasets for some cases, misrepresented SaaS data practices for others.</li>



<li>Contract lawyers and in-house counsel are suddenly very important in AI risk management, because <strong>data-use rights are now a negotiated economic term</strong>, not boilerplate.</li>
</ul>



<p>If your company builds or buys SaaS and AI, the practical takeaway is straightforward:</p>



<ul class="wp-block-list">
<li>Treat data-use clauses, training rights, and AI indemnities as <strong>core deal terms</strong>, not fine print.</li>



<li>Assume that any mismatch between what you say in marketing and what you do in product will be quoted back to you in a complaint.</li>



<li>Have a demand-letter playbook readyâ€”on both offense and defenseâ€”before you find your name next to Figma and Salesforce in the next wave of AI-training cases.</li>
</ul>



<!-- Calendly inline widget begin -->
<div class="calendly-inline-widget" data-url="https://calendly.com/sergei-tokmakov/30-minute-zoom-meeting?hide_gdpr_banner=1" style="min-width:320px;height:700px;"></div>
<script type="text/javascript" src="https://assets.calendly.com/assets/external/widget.js" async></script>
<!-- Calendly inline widget end -->
</div>
    </article>
  </main>

  <footer><p>Â© 2025 Terms.Law. All rights reserved.</p></footer>
</body>
</html>